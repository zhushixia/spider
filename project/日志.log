2020-02-13 14:13:36 engine.py[line:29]                   INFO: 开始运行时间：2020-02-13 14:13:36.522802
2020-02-13 14:13:36 engine.py[line:32]                   INFO: 结束运行时间：2020-02-13 14:13:36.866821
2020-02-13 14:13:36 engine.py[line:33]                   INFO: 耗时：0.34
2020-02-13 14:29:59 engine.py[line:29]                   INFO: 开始运行时间：2020-02-13 14:29:59.402019
2020-02-13 14:29:59 engine.py[line:32]                   INFO: 结束运行时间：2020-02-13 14:29:59.751039
2020-02-13 14:29:59 engine.py[line:33]                   INFO: 耗时：0.35
2020-02-13 14:34:26 engine.py[line:29]                   INFO: 开始运行时间：2020-02-13 14:34:26.199279
2020-02-13 15:37:51 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:37:51.225914
2020-02-13 15:38:56 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:38:56.533649
2020-02-13 15:38:56 engine.py[line:35]                   INFO: 结束运行时间：2020-02-13 15:38:56.534649
2020-02-13 15:38:56 engine.py[line:36]                   INFO: 耗时：0.00
2020-02-13 15:39:27 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:39:27.069396
2020-02-13 15:39:27 engine.py[line:35]                   INFO: 结束运行时间：2020-02-13 15:39:27.070396
2020-02-13 15:39:27 engine.py[line:36]                   INFO: 耗时：0.00
2020-02-13 15:40:17 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:40:17.111258
2020-02-13 15:40:17 engine.py[line:35]                   INFO: 结束运行时间：2020-02-13 15:40:17.112258
2020-02-13 15:40:17 engine.py[line:36]                   INFO: 耗时：0.00
2020-02-13 15:41:55 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:41:53.907795
2020-02-13 15:43:22 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:43:20.361740
2020-02-13 15:45:59 engine.py[line:32]                   INFO: 开始运行时间：2020-02-13 15:45:59.320831
2020-02-13 15:45:59 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-13 15:45:59 engine.py[line:35]                   INFO: 结束运行时间：2020-02-13 15:45:59.719854
2020-02-13 15:45:59 engine.py[line:36]                   INFO: 耗时：0.40
2020-02-14 10:11:56 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:11:56.535912
2020-02-14 10:11:56 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:13:52 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:13:52.981572
2020-02-14 10:13:57 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:16:15 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:16:15.465722
2020-02-14 10:16:15 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:20:45 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:20:45.961193
2020-02-14 10:20:46 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:26:49 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:26:49.951012
2020-02-14 10:26:50 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:28:46 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:28:46.997707
2020-02-14 10:28:47 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:29:18 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:29:18.966535
2020-02-14 10:29:19 downloader.py[line:19]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:30:46 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:30:46.326532
2020-02-14 10:30:46 downloader.py[line:20]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:31:05 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:31:05.539631
2020-02-14 10:31:06 downloader.py[line:21]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:41:16 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:41:16.181558
2020-02-14 10:41:16 downloader.py[line:21]                   INFO: <418 https://movie.douban.com/top250?start=0>
2020-02-14 10:42:07 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:42:07.019465
2020-02-14 10:42:07 downloader.py[line:21]                   INFO: <418 https://movie.douban.com/top250?start=0>
2020-02-14 10:43:21 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:43:21.783742
2020-02-14 10:43:22 downloader.py[line:22]                   INFO: <418 https://movie.douban.com/top250?start=0>
2020-02-14 10:43:49 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:43:49.285315
2020-02-14 10:44:16 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:44:16.549874
2020-02-14 10:44:16 downloader.py[line:22]                   INFO: <418 https://movie.douban.com/top250?start=0>
2020-02-14 10:44:49 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:44:49.137738
2020-02-14 10:44:49 downloader.py[line:22]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:45:11 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:45:11.501017
2020-02-14 10:45:11 downloader.py[line:22]                   INFO: <418 http://movie.douban.com/top250?start=0>
2020-02-14 10:49:01 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:49:01.150152
2020-02-14 10:49:01 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:02 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:02 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:02 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:03 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:03 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:03 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:04 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:04 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:05 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:05 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:05 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:06 downloader.py[line:22]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:49:06 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 10:49:06.095435
2020-02-14 10:49:06 engine.py[line:36]                   INFO: 耗时：4.95
2020-02-14 10:50:19 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:50:19.587639
2020-02-14 10:50:19 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:20 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:20 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:21 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:21 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:21 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:22 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:22 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:22 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:23 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:23 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:23 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:24 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:50:24 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 10:50:24.273907
2020-02-14 10:50:24 engine.py[line:36]                   INFO: 耗时：4.69
2020-02-14 10:51:38 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:51:38.547155
2020-02-14 10:51:39 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:39 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:40 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:40 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:41 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:41 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:42 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:43 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:43 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:43 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:44 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:44 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:45 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:45 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 10:51:45.046527
2020-02-14 10:51:45 engine.py[line:36]                   INFO: 耗时：6.50
2020-02-14 10:51:57 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:51:57.747253
2020-02-14 10:51:58 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:58 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:58 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:59 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:59 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:51:59 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:00 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:00 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:01 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:01 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:01 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:02 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:02 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:02 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 10:52:02.512526
2020-02-14 10:52:02 engine.py[line:36]                   INFO: 耗时：4.77
2020-02-14 10:52:57 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:52:57.992699
2020-02-14 10:52:58 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:58 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:59 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:52:59 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:09 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:53:09.623364
2020-02-14 10:53:10 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:10 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:10 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:11 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:11 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:11 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:12 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:12 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:12 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:13 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:13 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:13 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:14 downloader.py[line:19]                   INFO: <200 https://www.qiushibaike.com/>
2020-02-14 10:53:14 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 10:53:14.281631
2020-02-14 10:53:14 engine.py[line:36]                   INFO: 耗时：4.66
2020-02-14 10:56:16 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 10:56:16.159033
2020-02-14 11:05:21 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:05:21.333216
2020-02-14 11:06:37 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:06:37.364564
2020-02-14 11:07:13 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:07:13.427627
2020-02-14 11:08:15 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:08:15.577182
2020-02-14 11:08:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:16 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 11:08:16.125213
2020-02-14 11:08:16 engine.py[line:36]                   INFO: 耗时：0.55
2020-02-14 11:08:31 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:08:31.930117
2020-02-14 11:08:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:08:36 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 11:08:36.997407
2020-02-14 11:08:36 engine.py[line:36]                   INFO: 耗时：5.07
2020-02-14 11:35:38 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:35:38.655160
2020-02-14 11:35:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:38:35 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:38:35.774291
2020-02-14 11:38:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:53:59 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:53:59.741139
2020-02-14 11:54:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:54:05 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 11:54:05.223453
2020-02-14 11:54:05 engine.py[line:36]                   INFO: 耗时：5.48
2020-02-14 11:56:00 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:56:00.047020
2020-02-14 11:56:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:56:05 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 11:56:05.332322
2020-02-14 11:56:05 engine.py[line:36]                   INFO: 耗时：5.29
2020-02-14 11:58:18 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:58:18.622946
2020-02-14 11:58:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:49 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:58:49.411707
2020-02-14 11:58:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:58:54 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 11:58:54.829017
2020-02-14 11:58:54 engine.py[line:36]                   INFO: 耗时：5.42
2020-02-14 11:59:04 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 11:59:04.771586
2020-02-14 11:59:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 11:59:09 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 11:59:09.970883
2020-02-14 11:59:09 engine.py[line:36]                   INFO: 耗时：5.20
2020-02-14 12:00:00 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:00:00.654782
2020-02-14 12:01:04 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:01:04.085410
2020-02-14 12:01:55 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:01:55.185333
2020-02-14 12:10:03 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:10:03.091239
2020-02-14 12:10:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:10:19 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:10:19.207161
2020-02-14 12:10:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:10:52 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:10:52.023038
2020-02-14 12:10:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:11:04 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:11:04.981779
2020-02-14 12:11:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:11:05 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:11:05.526811
2020-02-14 12:11:05 engine.py[line:36]                   INFO: 耗时：0.55
2020-02-14 12:11:23 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:11:23.893861
2020-02-14 12:11:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:11:41 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:11:41.818886
2020-02-14 12:11:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:11:42 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:11:42.259912
2020-02-14 12:11:42 engine.py[line:36]                   INFO: 耗时：0.44
2020-02-14 12:12:03 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:12:03.943152
2020-02-14 12:12:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:12:49 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:12:49.267744
2020-02-14 12:12:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:12:50 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:12:50.127793
2020-02-14 12:12:50 engine.py[line:36]                   INFO: 耗时：0.86
2020-02-14 12:13:21 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:13:21.984615
2020-02-14 12:13:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:13:32 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:13:32.226201
2020-02-14 12:13:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:13:48 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:13:48.299121
2020-02-14 12:13:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:13:49 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:13:49.259176
2020-02-14 12:13:49 engine.py[line:36]                   INFO: 耗时：0.96
2020-02-14 12:14:08 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:14:08.750290
2020-02-14 12:14:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:14:09 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:14:09.661342
2020-02-14 12:14:09 engine.py[line:36]                   INFO: 耗时：0.91
2020-02-14 12:16:12 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:16:12.840388
2020-02-14 12:16:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:16:13 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:16:13.347417
2020-02-14 12:16:13 engine.py[line:36]                   INFO: 耗时：0.51
2020-02-14 12:16:41 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:16:41.612034
2020-02-14 12:16:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:16:42 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:16:42.134063
2020-02-14 12:16:42 engine.py[line:36]                   INFO: 耗时：0.52
2020-02-14 12:17:04 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:17:04.482342
2020-02-14 12:17:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:17:05 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:17:05.068375
2020-02-14 12:17:05 engine.py[line:36]                   INFO: 耗时：0.59
2020-02-14 12:18:20 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:18:20.097667
2020-02-14 12:18:20 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:18:20 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:18:20.911713
2020-02-14 12:18:20 engine.py[line:36]                   INFO: 耗时：0.81
2020-02-14 12:19:14 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:19:14.810796
2020-02-14 12:19:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:19:15 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:19:15.420831
2020-02-14 12:19:15 engine.py[line:36]                   INFO: 耗时：0.61
2020-02-14 12:19:26 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:19:26.903488
2020-02-14 12:19:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:19:28 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:19:28.021552
2020-02-14 12:19:28 engine.py[line:36]                   INFO: 耗时：1.12
2020-02-14 12:21:04 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:21:04.864091
2020-02-14 12:21:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:21:05 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:21:05.535129
2020-02-14 12:21:05 engine.py[line:36]                   INFO: 耗时：0.67
2020-02-14 12:21:13 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:21:13.957611
2020-02-14 12:21:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:21:14 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:21:14.639650
2020-02-14 12:21:14 engine.py[line:36]                   INFO: 耗时：0.68
2020-02-14 12:22:21 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:22:21.511475
2020-02-14 12:22:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:22:22 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:22:22.149511
2020-02-14 12:22:22 engine.py[line:36]                   INFO: 耗时：0.64
2020-02-14 12:22:34 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:22:34.339208
2020-02-14 12:22:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:22:34 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:22:34.775233
2020-02-14 12:22:34 engine.py[line:36]                   INFO: 耗时：0.44
2020-02-14 12:25:40 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:25:40.266843
2020-02-14 12:25:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:26:39 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:26:39.463229
2020-02-14 12:26:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:27:44 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:27:44.663958
2020-02-14 12:27:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:28:22 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:28:22.108100
2020-02-14 12:28:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:28:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-14 12:28:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-14 12:28:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-14 12:28:24 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-14 12:28:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-14 12:28:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-14 12:28:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-14 12:28:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-14 12:28:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-14 12:28:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-14 12:28:27 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:28:27.835427
2020-02-14 12:28:27 engine.py[line:36]                   INFO: 耗时：5.73
2020-02-14 12:29:50 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:29:50.718168
2020-02-14 12:29:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:29:55 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:29:55.345432
2020-02-14 12:29:55 engine.py[line:36]                   INFO: 耗时：4.63
2020-02-14 12:32:12 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 12:32:12.477276
2020-02-14 12:32:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:20 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 12:32:24 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-14 12:32:25 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-14 12:32:25 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-14 12:32:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-14 12:32:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-14 12:32:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-14 12:32:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-14 12:32:29 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-14 12:32:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-14 12:32:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-14 12:32:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-14 12:32:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-14 12:32:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-14 12:32:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-14 12:32:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-14 12:32:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-14 12:32:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-14 12:32:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-14 12:32:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-14 12:32:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-14 12:32:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-14 12:32:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-14 12:32:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-14 12:32:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-14 12:32:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-14 12:32:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-14 12:32:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-14 12:32:38 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-14 12:32:38 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-14 12:32:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-14 12:32:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450288/>
2020-02-14 12:32:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817865/>
2020-02-14 12:32:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/814773/>
2020-02-14 12:32:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817025/>
2020-02-14 12:32:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816699/>
2020-02-14 12:32:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816243/>
2020-02-14 12:32:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816141/>
2020-02-14 12:32:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815826/>
2020-02-14 12:32:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815763/>
2020-02-14 12:32:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815684/>
2020-02-14 12:32:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447292/>
2020-02-14 12:32:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675996/>
2020-02-14 12:32:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447317/>
2020-02-14 12:32:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/813759/>
2020-02-14 12:32:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675739/>
2020-02-14 12:32:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/809720/>
2020-02-14 12:32:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/801365/>
2020-02-14 12:32:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447543/>
2020-02-14 12:32:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/671684/>
2020-02-14 12:32:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447556/>
2020-02-14 12:32:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447558/>
2020-02-14 12:32:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/800214/>
2020-02-14 12:32:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799984/>
2020-02-14 12:32:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799718/>
2020-02-14 12:32:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798382/>
2020-02-14 12:32:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798337/>
2020-02-14 12:32:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798302/>
2020-02-14 12:32:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797865/>
2020-02-14 12:32:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797563/>
2020-02-14 12:32:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/796709/>
2020-02-14 12:32:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/796194/>
2020-02-14 12:32:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/794862/>
2020-02-14 12:32:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793902/>
2020-02-14 12:32:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793769/>
2020-02-14 12:32:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793067/>
2020-02-14 12:33:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/790398/>
2020-02-14 12:33:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/789520/>
2020-02-14 12:33:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788785/>
2020-02-14 12:33:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788516/>
2020-02-14 12:33:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788359/>
2020-02-14 12:33:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/666637/>
2020-02-14 12:33:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/453763/>
2020-02-14 12:33:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/787550/>
2020-02-14 12:33:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/787452/>
2020-02-14 12:33:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/785557/>
2020-02-14 12:33:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797020/>
2020-02-14 12:33:09 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450833/>
2020-02-14 12:33:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780992/>
2020-02-14 12:33:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780901/>
2020-02-14 12:33:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780437/>
2020-02-14 12:33:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780433/>
2020-02-14 12:33:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/779827/>
2020-02-14 12:33:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/779285/>
2020-02-14 12:33:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/452317/>
2020-02-14 12:33:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/778174/>
2020-02-14 12:33:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/778008/>
2020-02-14 12:33:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/452345/>
2020-02-14 12:33:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/777153/>
2020-02-14 12:33:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/775183/>
2020-02-14 12:33:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/773166/>
2020-02-14 12:33:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/772900/>
2020-02-14 12:33:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/654108/>
2020-02-14 12:33:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/772341/>
2020-02-14 12:33:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/771102/>
2020-02-14 12:33:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/770624/>
2020-02-14 12:33:19 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448090/>
2020-02-14 12:33:20 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450930/>
2020-02-14 12:33:20 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769660/>
2020-02-14 12:33:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769658/>
2020-02-14 12:33:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769591/>
2020-02-14 12:33:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769564/>
2020-02-14 12:33:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769133/>
2020-02-14 12:33:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/653082/>
2020-02-14 12:33:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/768667/>
2020-02-14 12:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/768203/>
2020-02-14 12:33:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/652565/>
2020-02-14 12:33:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/765826/>
2020-02-14 12:33:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/765824/>
2020-02-14 12:33:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/708519/>
2020-02-14 12:33:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448201/>
2020-02-14 12:33:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/764130/>
2020-02-14 12:33:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/763747/>
2020-02-14 12:33:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/763630/>
2020-02-14 12:33:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/650817/>
2020-02-14 12:33:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/762640/>
2020-02-14 12:33:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761999/>
2020-02-14 12:33:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761506/>
2020-02-14 12:33:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761445/>
2020-02-14 12:33:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761278/>
2020-02-14 12:33:38 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/451059/>
2020-02-14 12:33:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/759719/>
2020-02-14 12:33:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/759507/>
2020-02-14 12:33:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/759506/>
2020-02-14 12:33:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448331/>
2020-02-14 12:33:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758962/>
2020-02-14 12:33:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758905/>
2020-02-14 12:33:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/648378/>
2020-02-14 12:33:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758623/>
2020-02-14 12:33:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758428/>
2020-02-14 12:33:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758146/>
2020-02-14 12:33:45 engine.py[line:35]                   INFO: 结束运行时间：2020-02-14 12:33:45.459594
2020-02-14 12:33:45 engine.py[line:36]                   INFO: 耗时：92.98
2020-02-14 13:34:23 engine.py[line:32]                   INFO: 开始运行时间：2020-02-14 13:34:23.253664
2020-02-14 13:34:23 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 13:34:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 13:34:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:54:57 engine.py[line:33]                   INFO: 开始运行时间：2020-02-14 15:54:57.619082
2020-02-14 15:54:57 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 15:55:36 engine.py[line:33]                   INFO: 开始运行时间：2020-02-14 15:55:36.989334
2020-02-14 15:55:37 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 15:55:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:55:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:55:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:55:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:55:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:24 engine.py[line:33]                   INFO: 开始运行时间：2020-02-14 15:56:24.881073
2020-02-14 15:56:24 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 15:56:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 15:56:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-14 15:56:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-14 15:56:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-14 15:56:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-14 15:56:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-14 19:55:12 engine.py[line:33]                   INFO: 开始运行时间：2020-02-14 19:55:12.214550
2020-02-14 19:55:12 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 19:55:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:20 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 19:55:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:44:43 engine.py[line:35]                   INFO: 开始运行时间：2020-02-14 20:44:43.813516
2020-02-14 20:44:43 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 20:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:44:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:21 engine.py[line:35]                   INFO: 开始运行时间：2020-02-14 20:46:21.051077
2020-02-14 20:46:22 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 20:46:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:46:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-14 20:46:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-14 20:46:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-14 20:46:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-14 20:46:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-14 20:46:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-14 20:46:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-14 20:46:43 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-14 20:46:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-14 20:46:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-14 20:46:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-14 20:46:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-14 20:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-14 20:46:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-14 20:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-14 20:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-14 20:46:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-14 20:46:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-14 20:46:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-14 20:46:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-14 20:46:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-14 20:46:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-14 20:46:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-14 20:46:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-14 20:46:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-14 20:46:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-14 20:46:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-14 20:46:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-14 20:46:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-14 20:46:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-14 20:46:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450288/>
2020-02-14 20:46:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817865/>
2020-02-14 20:46:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/814773/>
2020-02-14 20:47:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817025/>
2020-02-14 20:47:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816699/>
2020-02-14 20:47:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816243/>
2020-02-14 20:47:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816141/>
2020-02-14 20:47:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815826/>
2020-02-14 20:47:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815763/>
2020-02-14 20:47:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815684/>
2020-02-14 20:47:04 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447292/>
2020-02-14 20:47:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675996/>
2020-02-14 20:47:05 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447317/>
2020-02-14 20:47:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/813759/>
2020-02-14 20:47:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675739/>
2020-02-14 20:47:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/809720/>
2020-02-14 20:47:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/801365/>
2020-02-14 20:47:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447543/>
2020-02-14 20:47:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/671684/>
2020-02-14 20:47:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447556/>
2020-02-14 20:47:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447558/>
2020-02-14 20:47:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/800214/>
2020-02-14 20:47:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799984/>
2020-02-14 20:47:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799718/>
2020-02-14 20:47:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798382/>
2020-02-14 20:47:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798337/>
2020-02-14 20:47:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798302/>
2020-02-14 20:47:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797865/>
2020-02-14 20:47:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797563/>
2020-02-14 20:47:20 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/796709/>
2020-02-14 20:47:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/796194/>
2020-02-14 20:47:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/794862/>
2020-02-14 20:47:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793902/>
2020-02-14 20:47:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793769/>
2020-02-14 20:47:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793067/>
2020-02-14 20:47:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/790398/>
2020-02-14 20:47:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/789520/>
2020-02-14 20:47:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788785/>
2020-02-14 20:47:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788516/>
2020-02-14 20:47:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788359/>
2020-02-14 20:47:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/666637/>
2020-02-14 20:47:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/453763/>
2020-02-14 20:53:44 engine.py[line:35]                   INFO: 开始运行时间：2020-02-14 20:53:44.973468
2020-02-14 20:54:32 engine.py[line:35]                   INFO: 开始运行时间：2020-02-14 20:54:32.305176
2020-02-14 20:54:32 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-14 20:54:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-14 20:54:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-14 20:54:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-14 20:54:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-14 20:54:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-14 20:55:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-14 20:55:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-14 20:55:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-14 20:55:02 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-14 20:55:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-14 20:55:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-14 20:55:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-14 20:55:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-14 20:55:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-14 20:55:04 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-14 20:55:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-14 20:55:05 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-14 20:55:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-14 20:55:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-14 20:55:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-14 20:55:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-14 20:55:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-14 20:55:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-14 20:55:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-14 20:55:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-14 20:55:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-14 20:55:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-14 20:55:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-14 20:55:09 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-14 20:55:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-14 20:55:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-14 20:55:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450288/>
2020-02-14 20:55:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817865/>
2020-02-14 20:55:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/814773/>
2020-02-14 20:55:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817025/>
2020-02-14 20:55:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816699/>
2020-02-14 20:55:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816243/>
2020-02-14 20:55:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816141/>
2020-02-14 20:55:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815826/>
2020-02-14 20:55:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815763/>
2020-02-14 20:55:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815684/>
2020-02-14 20:55:18 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447292/>
2020-02-14 20:55:20 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675996/>
2020-02-14 20:55:21 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447317/>
2020-02-14 20:55:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/813759/>
2020-02-14 20:55:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675739/>
2020-02-14 20:55:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/809720/>
2020-02-14 20:55:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/801365/>
2020-02-14 20:55:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447543/>
2020-02-14 20:55:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/671684/>
2020-02-14 20:55:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447556/>
2020-02-14 20:55:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447558/>
2020-02-14 20:55:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/800214/>
2020-02-14 20:55:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799984/>
2020-02-14 20:55:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799718/>
2020-02-14 20:55:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798382/>
2020-02-14 20:55:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798337/>
2020-02-14 20:55:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798302/>
2020-02-14 20:55:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797865/>
2020-02-14 20:55:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797563/>
2020-02-14 20:55:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/796709/>
2020-02-14 20:55:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/796194/>
2020-02-14 20:55:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/794862/>
2020-02-14 20:55:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793902/>
2020-02-14 20:55:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793769/>
2020-02-14 20:55:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793067/>
2020-02-14 20:55:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/790398/>
2020-02-14 20:55:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/789520/>
2020-02-14 20:55:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788785/>
2020-02-14 20:55:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788516/>
2020-02-14 20:55:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788359/>
2020-02-14 20:55:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/666637/>
2020-02-14 20:55:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/453763/>
2020-02-14 20:55:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/787550/>
2020-02-14 20:56:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/787452/>
2020-02-14 20:56:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/785557/>
2020-02-14 20:56:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797020/>
2020-02-14 20:56:04 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450833/>
2020-02-14 20:56:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780992/>
2020-02-14 20:56:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780901/>
2020-02-14 20:56:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780437/>
2020-02-14 20:56:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780433/>
2020-02-14 20:56:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/779827/>
2020-02-14 20:56:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/779285/>
2020-02-14 20:56:08 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/452317/>
2020-02-14 20:56:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/778174/>
2020-02-14 20:56:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/778008/>
2020-02-14 20:56:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/452345/>
2020-02-14 20:56:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/777153/>
2020-02-14 20:56:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/775183/>
2020-02-14 20:56:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/773166/>
2020-02-14 20:56:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/772900/>
2020-02-14 20:56:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/654108/>
2020-02-14 20:56:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/772341/>
2020-02-14 20:56:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/771102/>
2020-02-14 20:56:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/770624/>
2020-02-14 20:56:16 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448090/>
2020-02-14 20:56:16 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450930/>
2020-02-14 20:56:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769660/>
2020-02-14 20:56:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769658/>
2020-02-14 20:56:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769591/>
2020-02-14 20:56:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769564/>
2020-02-14 20:56:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769133/>
2020-02-14 20:56:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/653082/>
2020-02-14 20:56:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/768667/>
2020-02-14 20:56:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/768203/>
2020-02-14 20:56:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/652565/>
2020-02-14 20:56:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/765826/>
2020-02-14 20:56:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/765824/>
2020-02-14 20:56:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/708519/>
2020-02-14 20:56:25 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448201/>
2020-02-14 20:56:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/764130/>
2020-02-14 20:56:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/763747/>
2020-02-14 20:56:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/763630/>
2020-02-14 20:56:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/650817/>
2020-02-14 20:56:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/762640/>
2020-02-14 20:56:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761999/>
2020-02-14 20:56:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761506/>
2020-02-14 20:56:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761445/>
2020-02-14 20:56:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761278/>
2020-02-14 20:56:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/451059/>
2020-02-14 20:56:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/759719/>
2020-02-14 20:56:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/759507/>
2020-02-14 20:56:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/759506/>
2020-02-14 20:56:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448331/>
2020-02-14 20:56:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758962/>
2020-02-14 20:56:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758905/>
2020-02-14 20:56:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/648378/>
2020-02-14 20:56:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758623/>
2020-02-14 20:56:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758428/>
2020-02-14 20:56:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758146/>
2020-02-14 20:56:34 engine.py[line:38]                   INFO: 结束运行时间：2020-02-14 20:56:34.750179
2020-02-14 20:56:34 engine.py[line:39]                   INFO: 耗时：122.45
2020-02-15 09:56:35 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 09:56:35.916795
2020-02-15 09:56:36 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 09:56:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-15 09:56:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:36 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 10:00:36.914579
2020-02-15 10:00:37 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 10:00:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-15 10:00:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-15 12:16:12 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 12:16:12.491907
2020-02-15 12:16:12 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 12:16:12 engine.py[line:38]                   INFO: 结束运行时间：2020-02-15 12:16:12.621915
2020-02-15 12:16:12 engine.py[line:39]                   INFO: 耗时：0.13
2020-02-15 12:16:27 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 12:16:27.788782
2020-02-15 12:16:27 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 12:16:27 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 12:16:28 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 12:16:28 engine.py[line:38]                   INFO: 结束运行时间：2020-02-15 12:16:28.098800
2020-02-15 12:16:28 engine.py[line:39]                   INFO: 耗时：0.31
2020-02-15 13:48:21 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 13:48:21.578153
2020-02-15 13:48:21 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 13:48:22 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 13:48:22 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 13:48:22 engine.py[line:38]                   INFO: 结束运行时间：2020-02-15 13:48:22.221190
2020-02-15 13:48:22 engine.py[line:39]                   INFO: 耗时：0.64
2020-02-15 14:04:14 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:04:14.750671
2020-02-15 14:04:14 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:04:15 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:04:15 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:04:15 engine.py[line:38]                   INFO: 结束运行时间：2020-02-15 14:04:15.860735
2020-02-15 14:04:15 engine.py[line:39]                   INFO: 耗时：1.11
2020-02-15 14:04:29 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:04:29.305504
2020-02-15 14:04:29 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:04:29 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:04:29 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:04:29 engine.py[line:38]                   INFO: 结束运行时间：2020-02-15 14:04:29.863536
2020-02-15 14:04:29 engine.py[line:39]                   INFO: 耗时：0.56
2020-02-15 14:06:28 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:06:28.113299
2020-02-15 14:06:28 engine.py[line:36]                   INFO: 指纹中的数据：0
2020-02-15 14:06:28 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:06:28 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:06:28 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:06:28 engine.py[line:39]                   INFO: 结束运行时间：2020-02-15 14:06:28.912345
2020-02-15 14:06:28 engine.py[line:40]                   INFO: 耗时：0.80
2020-02-15 14:07:30 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:07:30.979895
2020-02-15 14:07:30 engine.py[line:36]                   INFO: 指纹中的数据：0
2020-02-15 14:07:31 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:07:31 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:07:31 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:07:31 engine.py[line:39]                   INFO: 结束运行时间：2020-02-15 14:07:31.249910
2020-02-15 14:07:31 engine.py[line:40]                   INFO: 耗时：0.27
2020-02-15 14:08:25 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:08:25.902036
2020-02-15 14:08:25 engine.py[line:36]                   INFO: 指纹中的数据：0
2020-02-15 14:08:25 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:08:26 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:08:26 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:08:26 engine.py[line:39]                   INFO: 结束运行时间：2020-02-15 14:08:26.185053
2020-02-15 14:08:26 engine.py[line:40]                   INFO: 耗时：0.28
2020-02-15 14:09:00 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:09:00.101992
2020-02-15 14:09:00 engine.py[line:36]                   INFO: 指纹中的数据：set()
2020-02-15 14:09:00 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:09:00 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:09:00 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:09:00 engine.py[line:39]                   INFO: 结束运行时间：2020-02-15 14:09:00.367008
2020-02-15 14:09:00 engine.py[line:40]                   INFO: 耗时：0.27
2020-02-15 14:09:53 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:09:53.576051
2020-02-15 14:09:53 engine.py[line:36]                   INFO: 指纹中的数据：set()
2020-02-15 14:09:53 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:09:53 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:09:53 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:09:53 engine.py[line:39]                   INFO: 结束运行时间：2020-02-15 14:09:53.906070
2020-02-15 14:09:53 engine.py[line:40]                   INFO: 耗时：0.33
2020-02-15 14:13:29 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:13:29.869422
2020-02-15 14:13:29 engine.py[line:36]                   INFO: 指纹中的数据：set()
2020-02-15 14:14:26 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:14:26.401656
2020-02-15 14:14:26 engine.py[line:36]                   INFO: 指纹中的数据：set()
2020-02-15 14:14:26 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:14:26 engine.py[line:39]                   INFO: 结束运行时间：2020-02-15 14:14:26.712674
2020-02-15 14:14:26 engine.py[line:40]                   INFO: 耗时：0.31
2020-02-15 14:18:01 engine.py[line:35]                   INFO: 开始运行时间：2020-02-15 14:18:01.943984
2020-02-15 14:18:01 engine.py[line:36]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031B5830>}
2020-02-15 14:18:01 engine.py[line:37]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 14:18:01 engine.py[line:38]                   INFO: 开启的下载中间件有：[]
2020-02-15 14:18:01 engine.py[line:39]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031B5DB0>, <pipelines.DoubanPipeline object at 0x031B5DD0>]
2020-02-15 14:18:02 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 14:18:02 engine.py[line:42]                   INFO: 结束运行时间：2020-02-15 14:18:02.569020
2020-02-15 14:18:02 engine.py[line:43]                   INFO: 耗时：0.63
2020-02-15 15:55:51 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:55:51.751718
2020-02-15 15:55:51 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0355A550>}
2020-02-15 15:55:51 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:55:51 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:55:51 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0355AAB0>, <pipelines.DoubanPipeline object at 0x0355AAD0>]
2020-02-15 15:56:31 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:56:31.287979
2020-02-15 15:56:31 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031FA550>}
2020-02-15 15:56:31 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:56:31 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:56:31 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031FAAB0>, <pipelines.DoubanPipeline object at 0x031FAAD0>]
2020-02-15 15:57:08 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:57:08.874129
2020-02-15 15:57:08 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0355B5F0>}
2020-02-15 15:57:08 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:57:08 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:57:08 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0355BA70>, <pipelines.DoubanPipeline object at 0x0355BA90>]
2020-02-15 15:59:01 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:59:01.502571
2020-02-15 15:59:01 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0355A570>}
2020-02-15 15:59:01 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:59:01 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:59:01 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0355AAD0>, <pipelines.DoubanPipeline object at 0x0355AAF0>]
2020-02-15 15:59:02 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 15:59:02 engine.py[line:47]                   INFO: 结束运行时间：2020-02-15 15:59:02.301617
2020-02-15 15:59:02 engine.py[line:48]                   INFO: 耗时：0.80
2020-02-15 15:59:10 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:59:10.857106
2020-02-15 15:59:10 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03248570>}
2020-02-15 15:59:10 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:59:10 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:59:10 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03248AD0>, <pipelines.DoubanPipeline object at 0x03248AF0>]
2020-02-15 15:59:24 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:59:24.495886
2020-02-15 15:59:24 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03568570>}
2020-02-15 15:59:24 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:59:24 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:59:24 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568AD0>, <pipelines.DoubanPipeline object at 0x03568AF0>]
2020-02-15 15:59:42 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:59:42.351907
2020-02-15 15:59:42 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03568570>}
2020-02-15 15:59:42 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:59:42 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:59:42 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568AD0>, <pipelines.DoubanPipeline object at 0x03568AF0>]
2020-02-15 15:59:54 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 15:59:54.524604
2020-02-15 15:59:54 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03568570>}
2020-02-15 15:59:54 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 15:59:54 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 15:59:54 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568AD0>, <pipelines.DoubanPipeline object at 0x03568AF0>]
2020-02-15 16:00:52 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:00:52.261906
2020-02-15 16:00:52 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8570>}
2020-02-15 16:00:52 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:00:52 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:00:52 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8AD0>, <pipelines.DoubanPipeline object at 0x031F8AF0>]
2020-02-15 16:01:30 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:01:30.373086
2020-02-15 16:01:30 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x039863F0>}
2020-02-15 16:01:30 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:01:30 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:01:30 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x039A53F0>, <pipelines.DoubanPipeline object at 0x039A5470>]
2020-02-15 16:03:43 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:03:43.280688
2020-02-15 16:03:43 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8570>}
2020-02-15 16:03:43 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:03:43 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:03:43 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8AD0>, <pipelines.DoubanPipeline object at 0x031F8AF0>]
2020-02-15 16:05:10 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:05:10.377669
2020-02-15 16:05:10 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8570>}
2020-02-15 16:05:10 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:05:10 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:05:10 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8A90>, <pipelines.DoubanPipeline object at 0x031F8AB0>]
2020-02-15 16:05:35 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:05:35.832125
2020-02-15 16:05:35 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x035BA570>, 'doubai': <spiders.douban.DoubanSpider object at 0x035BA790>}
2020-02-15 16:05:35 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:05:35 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:05:35 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x035BAAF0>, <pipelines.DoubanPipeline object at 0x035BAB10>]
2020-02-15 16:06:59 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:06:59.710923
2020-02-15 16:06:59 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03568330>, 'doubai': <spiders.douban.DoubanSpider object at 0x03568750>}
2020-02-15 16:06:59 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:06:59 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:06:59 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568AB0>, <pipelines.DoubanPipeline object at 0x03568AD0>]
2020-02-15 16:07:01 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:07:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:07:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:07:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:02 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:10:02.151358
2020-02-15 16:10:02 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031EA570>, 'doubai': <spiders.douban.DoubanSpider object at 0x031EA790>}
2020-02-15 16:10:02 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:10:02 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:10:02 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031EAAF0>, <pipelines.DoubanPipeline object at 0x031EAB10>]
2020-02-15 16:10:22 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:10:22.696533
2020-02-15 16:10:22 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0355A550>, 'doubai': <spiders.douban.DoubanSpider object at 0x0355A770>}
2020-02-15 16:10:22 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:10:22 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:10:22 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0355AAD0>, <pipelines.DoubanPipeline object at 0x0355AAF0>]
2020-02-15 16:10:24 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:10:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:10:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:11:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:13:52 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:13:52.911557
2020-02-15 16:13:52 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:13:52 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:13:52 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:13:52 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:13:55 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:14:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:17 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:14:17.220947
2020-02-15 16:14:17 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0356A590>, 'doubai': <spiders.douban.DoubanSpider object at 0x0356A7B0>}
2020-02-15 16:14:17 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:14:17 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:14:17 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0356AB10>, <pipelines.DoubanPipeline object at 0x0356AB30>]
2020-02-15 16:14:25 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:14:25.043394
2020-02-15 16:14:25 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:14:25 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:14:25 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:14:25 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:14:26 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:14:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:14:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:15:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:15:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:16:43 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:16:43.966340
2020-02-15 16:16:43 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:16:43 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:16:43 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:16:43 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:17:07 engine.py[line:120]                   ERROR: HTTPConnectionPool(host='www.baidu.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x032A65D0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))
Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "D:\Envs\meiduo\lib\site-packages\urllib3\util\connection.py", line 61, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\socket.py", line 745, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11004] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x032A65D0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "D:\Envs\meiduo\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='www.baidu.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x032A65D0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 118, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 71, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "F:\Tencent\temp\scrapy_plus\cores\downloader.py", line 14, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params)
  File "D:\Envs\meiduo\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='www.baidu.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x032A65D0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))
2020-02-15 16:17:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:17:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:17:58 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:17:58.364596
2020-02-15 16:17:58 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:17:58 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:17:58 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:17:58 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:17:58 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:17:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:18:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:18:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:37 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:19:37.755281
2020-02-15 16:19:37 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:19:37 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:19:37 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:19:37 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:19:52 engine.py[line:120]                   ERROR: HTTPConnectionPool(host='www.baidu.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x03256230>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))
Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connection.py", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "D:\Envs\meiduo\lib\site-packages\urllib3\util\connection.py", line 61, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\socket.py", line 745, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11004] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connectionpool.py", line 672, in urlopen
    chunked=chunked,
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connectionpool.py", line 387, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connection.py", line 184, in connect
    conn = self._new_conn()
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connection.py", line 169, in _new_conn
    self, "Failed to establish a new connection: %s" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x03256230>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\requests\adapters.py", line 449, in send
    timeout=timeout
  File "D:\Envs\meiduo\lib\site-packages\urllib3\connectionpool.py", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "D:\Envs\meiduo\lib\site-packages\urllib3\util\retry.py", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='www.baidu.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x03256230>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 118, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 71, in _execute_request_response_item
    response = self.downloader.get_response(request)
  File "F:\Tencent\temp\scrapy_plus\cores\downloader.py", line 14, in get_response
    resp = requests.get(request.url, headers=request.headers, params=request.params)
  File "D:\Envs\meiduo\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\api.py", line 60, in request
    return session.request(method=method, url=url, **kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\sessions.py", line 533, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\sessions.py", line 646, in send
    r = adapter.send(request, **kwargs)
  File "D:\Envs\meiduo\lib\site-packages\requests\adapters.py", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='www.baidu.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x03256230>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))
2020-02-15 16:19:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 16:19:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-15 16:19:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 16:19:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 16:19:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-15 16:19:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-15 16:19:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 16:19:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 16:19:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 16:19:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450288/>
2020-02-15 16:19:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817865/>
2020-02-15 16:19:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817025/>
2020-02-15 16:19:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/814773/>
2020-02-15 16:19:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816699/>
2020-02-15 16:19:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816243/>
2020-02-15 16:19:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816141/>
2020-02-15 16:19:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815826/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815763/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447558/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815684/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799718/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/799984/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/800214/>
2020-02-15 16:19:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798382/>
2020-02-15 16:20:00 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/798302/>
2020-02-15 16:20:00 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/797563/>
2020-02-15 16:20:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/798337/>
2020-02-15 16:20:00 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/796709/>
2020-02-15 16:20:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447292/>
2020-02-15 16:20:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675996/>
2020-02-15 16:20:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447317/>
2020-02-15 16:20:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/797865/>
2020-02-15 16:20:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/675739/>
2020-02-15 16:20:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/813759/>
2020-02-15 16:20:01 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/801365/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/809720/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447543/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/671684/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447556/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/666637/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/453763/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/785557/>
2020-02-15 16:20:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/787452/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/787550/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/797020/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450833/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/780901/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/780437/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/796194/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/794862/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/780992/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/793769/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/793902/>
2020-02-15 16:20:03 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/793067/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/790398/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/788785/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/789520/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/788516/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/780433/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/788359/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/779827/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/779285/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/778174/>
2020-02-15 16:20:04 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/452317/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/452345/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/777153/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/778008/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/773166/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/775183/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/772900/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/772341/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/770624/>
2020-02-15 16:20:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/654108/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/771102/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448090/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450930/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/769658/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/769591/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/769660/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/769564/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/769133/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/653082/>
2020-02-15 16:20:06 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/768203/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/768667/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/765826/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/765824/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448201/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/652565/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/764130/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/763747/>
2020-02-15 16:20:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/708519/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/763630/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/762640/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/650817/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/761999/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/761506/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/761445/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/451059/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/759719/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/761278/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/759507/>
2020-02-15 16:20:08 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/759506/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/448331/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/758962/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/758623/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/648378/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/758905/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/758428/>
2020-02-15 16:20:09 downloader.py[line:19]                   INFO: <503 https://www.guokr.com//post/758146/>
2020-02-15 16:23:09 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:23:09.746406
2020-02-15 16:23:09 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x035685B0>, 'doubai': <spiders.douban.DoubanSpider object at 0x035687D0>}
2020-02-15 16:23:09 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:23:09 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:23:09 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568B30>, <pipelines.DoubanPipeline object at 0x03568B50>]
2020-02-15 16:23:09 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=4&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=5&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=7&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=8&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=6&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=10&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=11&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=9&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=12&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=13&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 16:23:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/450288/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817865/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/814773/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816699/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/817025/>
2020-02-15 16:23:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816243/>
2020-02-15 16:23:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815826/>
2020-02-15 16:23:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815763/>
2020-02-15 16:23:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/816141/>
2020-02-15 16:23:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/815684/>
2020-02-15 16:23:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 16:23:32 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:23:32.203690
2020-02-15 16:23:32 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03568590>, 'doubai': <spiders.douban.DoubanSpider object at 0x035687B0>}
2020-02-15 16:23:32 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:23:32 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:23:32 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568B10>, <pipelines.DoubanPipeline object at 0x03568B30>]
2020-02-15 16:23:32 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:23:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-15 16:23:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-15 16:23:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 16:23:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-15 16:23:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 16:23:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 16:23:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 16:23:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 16:23:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 16:23:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 16:23:33 engine.py[line:47]                   INFO: 结束运行时间：2020-02-15 16:23:33.630772
2020-02-15 16:23:33 engine.py[line:48]                   INFO: 耗时：1.43
2020-02-15 16:23:49 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:23:49.031653
2020-02-15 16:23:49 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03208590>, 'doubai': <spiders.douban.DoubanSpider object at 0x032087B0>}
2020-02-15 16:23:49 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:23:49 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:23:49 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03208B10>, <pipelines.DoubanPipeline object at 0x03208B30>]
2020-02-15 16:23:49 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:23:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 16:23:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-15 16:23:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 16:23:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 16:23:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 16:23:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 16:23:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 16:23:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 16:23:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 16:23:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 16:23:50 engine.py[line:47]                   INFO: 结束运行时间：2020-02-15 16:23:50.441733
2020-02-15 16:23:50 engine.py[line:48]                   INFO: 耗时：1.41
2020-02-15 16:23:53 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:23:53.189891
2020-02-15 16:23:53 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:23:53 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:23:53 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:23:53 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:23:53 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:23:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:23:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 16:23:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 16:23:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 16:23:54 engine.py[line:47]                   INFO: 结束运行时间：2020-02-15 16:23:54.805983
2020-02-15 16:23:54 engine.py[line:48]                   INFO: 耗时：1.62
2020-02-15 16:24:04 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:24:04.369530
2020-02-15 16:24:04 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031F8590>, 'doubai': <spiders.douban.DoubanSpider object at 0x031F87B0>}
2020-02-15 16:24:04 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:24:04 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:24:04 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031F8B10>, <pipelines.DoubanPipeline object at 0x031F8B30>]
2020-02-15 16:24:04 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:24:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:24:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:24:04 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 16:24:05 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 16:24:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 16:24:07 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 16:24:08 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 16:24:08 engine.py[line:47]                   INFO: 结束运行时间：2020-02-15 16:24:08.077742
2020-02-15 16:24:08 engine.py[line:48]                   INFO: 耗时：3.71
2020-02-15 16:24:10 engine.py[line:40]                   INFO: 开始运行时间：2020-02-15 16:24:10.864902
2020-02-15 16:24:10 engine.py[line:41]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03568590>, 'doubai': <spiders.douban.DoubanSpider object at 0x035687B0>}
2020-02-15 16:24:10 engine.py[line:42]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 16:24:10 engine.py[line:43]                   INFO: 开启的下载中间件有：[]
2020-02-15 16:24:10 engine.py[line:44]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03568B10>, <pipelines.DoubanPipeline object at 0x03568B30>]
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-15 16:24:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 16:24:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 16:24:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 16:24:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 16:24:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 16:24:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 16:24:14 engine.py[line:47]                   INFO: 结束运行时间：2020-02-15 16:24:14.173091
2020-02-15 16:24:14 engine.py[line:48]                   INFO: 耗时：3.31
2020-02-15 18:44:38 engine.py[line:42]                   INFO: 开始运行时间：2020-02-15 18:44:38.037584
2020-02-15 18:44:38 engine.py[line:43]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x038723D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x038C5710>}
2020-02-15 18:44:38 engine.py[line:44]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 18:44:38 engine.py[line:45]                   INFO: 开启的下载中间件有：[]
2020-02-15 18:44:38 engine.py[line:46]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x038C5B90>, <pipelines.DoubanPipeline object at 0x038C5BB0>]
2020-02-15 18:44:38 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 18:44:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:44:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:44:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 18:44:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 18:44:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 18:44:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 18:44:42 engine.py[line:49]                   INFO: 结束运行时间：2020-02-15 18:44:42.009811
2020-02-15 18:44:42 engine.py[line:50]                   INFO: 耗时：3.97
2020-02-15 18:44:56 engine.py[line:42]                   INFO: 开始运行时间：2020-02-15 18:44:56.232624
2020-02-15 18:44:56 engine.py[line:43]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03E4B070>, 'doubai': <spiders.douban.DoubanSpider object at 0x03E9D3B0>}
2020-02-15 18:44:56 engine.py[line:44]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 18:44:56 engine.py[line:45]                   INFO: 开启的下载中间件有：[]
2020-02-15 18:44:56 engine.py[line:46]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03E9D830>, <pipelines.DoubanPipeline object at 0x03E9D850>]
2020-02-15 18:44:56 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 18:44:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:44:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:44:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-15 18:44:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 18:44:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 18:44:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 18:44:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 18:44:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 18:44:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 18:44:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 18:44:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 18:44:59 engine.py[line:49]                   INFO: 结束运行时间：2020-02-15 18:44:59.535813
2020-02-15 18:44:59 engine.py[line:50]                   INFO: 耗时：3.30
2020-02-15 18:46:44 engine.py[line:42]                   INFO: 开始运行时间：2020-02-15 18:46:44.685026
2020-02-15 18:46:44 engine.py[line:43]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x031A9FB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0320A2F0>}
2020-02-15 18:46:44 engine.py[line:44]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 18:46:44 engine.py[line:45]                   INFO: 开启的下载中间件有：[]
2020-02-15 18:46:44 engine.py[line:46]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0320A770>, <pipelines.DoubanPipeline object at 0x0320A790>]
2020-02-15 18:46:44 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-15 18:46:45 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 18:46:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 18:46:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 18:46:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 18:46:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 18:46:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 18:46:48 engine.py[line:49]                   INFO: 结束运行时间：2020-02-15 18:46:48.218228
2020-02-15 18:46:48 engine.py[line:50]                   INFO: 耗时：3.53
2020-02-15 18:53:47 engine.py[line:42]                   INFO: 开始运行时间：2020-02-15 18:53:47.777225
2020-02-15 18:53:47 engine.py[line:43]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03199FB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x031FA2F0>}
2020-02-15 18:53:47 engine.py[line:44]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 18:53:47 engine.py[line:45]                   INFO: 开启的下载中间件有：[]
2020-02-15 18:53:47 engine.py[line:46]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031FA770>, <pipelines.DoubanPipeline object at 0x031FA790>]
2020-02-15 18:53:47 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 18:53:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:53:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:53:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:53:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 18:53:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-15 18:53:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-15 18:53:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-15 18:53:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 18:53:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 18:53:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 18:53:52 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 18:53:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 18:53:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 18:53:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 18:53:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 18:53:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 18:53:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 18:53:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 18:53:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 18:53:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 18:53:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 18:53:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 18:53:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 18:53:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 18:53:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 18:53:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 18:53:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 18:53:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 18:54:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 18:54:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 18:54:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 18:54:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 18:54:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 18:54:01 engine.py[line:49]                   INFO: 结束运行时间：2020-02-15 18:54:01.907033
2020-02-15 18:54:01 engine.py[line:50]                   INFO: 耗时：14.13
2020-02-15 18:54:25 engine.py[line:42]                   INFO: 开始运行时间：2020-02-15 18:54:25.696394
2020-02-15 18:54:25 engine.py[line:43]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03179F70>, 'doubai': <spiders.douban.DoubanSpider object at 0x031EA2B0>}
2020-02-15 18:54:25 engine.py[line:44]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 18:54:25 engine.py[line:45]                   INFO: 开启的下载中间件有：[]
2020-02-15 18:54:25 engine.py[line:46]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x031EA730>, <pipelines.DoubanPipeline object at 0x031EA750>]
2020-02-15 18:54:25 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-15 18:54:26 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-15 18:54:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-15 18:54:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-15 18:54:29 engine.py[line:49]                   INFO: 结束运行时间：2020-02-15 18:54:29.021584
2020-02-15 18:54:29 engine.py[line:50]                   INFO: 耗时：3.33
2020-02-15 21:27:49 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:27:49.894009
2020-02-15 21:27:49 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8B0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BAF0>}
2020-02-15 21:27:49 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:27:49 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:27:49 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BFB0>, <pipelines.DoubanPipeline object at 0x033130B0>]
2020-02-15 21:33:43 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:33:43.787250
2020-02-15 21:33:43 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0332B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0332BB50>}
2020-02-15 21:33:43 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:33:43 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:33:43 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03336030>, <pipelines.DoubanPipeline object at 0x03336110>]
2020-02-15 21:33:43 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 21:36:00 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:36:00.650078
2020-02-15 21:36:00 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0335B8D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0335BB10>}
2020-02-15 21:36:00 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:36:00 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:36:00 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03366030>, <pipelines.DoubanPipeline object at 0x033660D0>]
2020-02-15 21:39:55 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:39:55.708523
2020-02-15 21:39:55 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB10>}
2020-02-15 21:39:55 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:39:55 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:39:55 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x033160D0>]
2020-02-15 21:39:55 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 21:42:52 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:42:52.170616
2020-02-15 21:42:52 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 21:42:52 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:42:52 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:42:52 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 21:42:52 engine.py[line:128]                   ERROR: Connection not ready
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 1003, in get_connection
    raise ConnectionError('Connection not ready')
redis.exceptions.ConnectionError: Connection not ready
2020-02-15 21:43:02 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:43:02.817225
2020-02-15 21:43:02 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 21:43:02 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:43:02 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:43:02 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 21:43:02 engine.py[line:128]                   ERROR: Error while reading from socket: (10053, '您的主机中的软件中止了一个已建立的连接。', None, 10053, None)
Traceback (most recent call last):
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 182, in _read_from_socket
    data = recv(self._sock, socket_read_size)
  File "D:\Envs\meiduo\lib\site-packages\redis\_compat.py", line 58, in recv
    return sock.recv(*args, **kwargs)
ConnectionAbortedError: [WinError 10053] 您的主机中的软件中止了一个已建立的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 637, in read_response
    response = self._parser.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 290, in read_response
    response = self._buffer.readline()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 224, in readline
    self._read_from_socket()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 199, in _read_from_socket
    (e.args,))
redis.exceptions.ConnectionError: Error while reading from socket: (10053, '您的主机中的软件中止了一个已建立的连接。', None, 10053, None)
2020-02-15 21:47:48 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:47:48.262552
2020-02-15 21:47:48 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 21:47:48 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:47:48 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:47:48 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03314030>, <pipelines.DoubanPipeline object at 0x03314110>]
2020-02-15 21:47:48 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 21:55:50 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:55:50.826153
2020-02-15 21:55:50 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 21:55:50 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:55:50 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:55:50 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 21:55:50 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 21:56:33 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:56:33.122572
2020-02-15 21:56:33 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 21:56:33 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:56:33 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:56:33 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 21:56:33 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 21:59:10 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:59:10.437570
2020-02-15 21:59:10 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB10>}
2020-02-15 21:59:10 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:59:10 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:59:10 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x033160D0>]
2020-02-15 21:59:28 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 21:59:28.938628
2020-02-15 21:59:28 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 21:59:28 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 21:59:28 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 21:59:28 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 21:59:28 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 22:04:25 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 22:04:25.156571
2020-02-15 22:04:25 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0331B8D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0331BB10>}
2020-02-15 22:04:25 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 22:04:25 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 22:04:25 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03326030>, <pipelines.DoubanPipeline object at 0x033260D0>]
2020-02-15 22:04:25 engine.py[line:128]                   ERROR: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 68, in _start_request
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 775, in execute_command
    return self.parse_response(connection, command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 789, in parse_response
    response = connection.read_response()
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 642, in read_response
    raise response
redis.exceptions.ResponseError: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect from external computers to Redis you may adopt one of the following solutions: 1) Just disable protected mode sending the command 'CONFIG SET protected-mode no' from the loopback interface by connecting to Redis from the same host the server is running, however MAKE SURE Redis is not publicly accessible from internet if you do so. Use CONFIG REWRITE to make this change permanent. 2) Alternatively you can just disable the protected mode by editing the Redis configuration file, and setting the protected mode option to 'no', and then restarting the server. 3) If you started the server manually just for testing, restart it with the '--protected-mode no' option. 4) Setup a bind address or an authentication password. NOTE: You only need to do one of the above things in order for the server to start accepting connections from the outside.
2020-02-15 22:04:25 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 22:04:25 engine.py[line:128]                   ERROR: Connection not ready
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 100, in _execute_request_response_item
    self.collector.incr(self.collector.request_nums)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 41, in request_nums
    return self.get(self.request_nums_key)
  File "F:\Tencent\temp\scrapy_plus\utils\stats_collector.py", line 26, in get
    ret = self.redis.get(key)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 1264, in get
    return self.execute_command('GET', name)
  File "D:\Envs\meiduo\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "D:\Envs\meiduo\lib\site-packages\redis\connection.py", line 1003, in get_connection
    raise ConnectionError('Connection not ready')
redis.exceptions.ConnectionError: Connection not ready
2020-02-15 23:47:04 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:47:04.681875
2020-02-15 23:47:04 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8F0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB30>}
2020-02-15 23:47:04 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:47:04 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:47:04 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x033160F0>]
2020-02-15 23:47:04 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:47:04 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:47:04.695876
2020-02-15 23:47:04 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-15 23:47:04 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:47:04 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:47:04 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:47:04 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:47:36 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:47:36.443692
2020-02-15 23:47:36 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B970>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BBB0>}
2020-02-15 23:47:36 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:47:36 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:47:36 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x032ED090>, <pipelines.DoubanPipeline object at 0x032ED170>]
2020-02-15 23:47:36 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:47:36 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:47:36.464693
2020-02-15 23:47:36 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-15 23:47:36 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:47:36 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:47:36 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:47:36 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:49:10 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:49:10.287059
2020-02-15 23:49:10 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-15 23:49:10 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:49:10 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:49:10 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316050>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-15 23:49:10 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:49:10.305061
2020-02-15 23:49:10 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-15 23:49:10 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:49:10 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:49:10 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:49:12 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:49:12.183168
2020-02-15 23:49:12 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04120CF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04120890>}
2020-02-15 23:49:12 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:49:12 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:49:12 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x04120DB0>, <pipelines.DoubanPipeline object at 0x04120E30>]
2020-02-15 23:49:12 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:49:12.195169
2020-02-15 23:49:12 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-15 23:49:12 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:49:12 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:49:12 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:49:12 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:49:12 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:51:31 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:51:31.182118
2020-02-15 23:51:31 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 23:51:31 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:51:31 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:51:31 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 23:51:31 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:51:31 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:51:31 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-15 23:51:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-15 23:51:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-15 23:51:34 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:51:34.190290
2020-02-15 23:51:34 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-15 23:51:34 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:51:34 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:51:34 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:51:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-15 23:51:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-15 23:54:50 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:54:50.986546
2020-02-15 23:54:50 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04192CF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04192890>}
2020-02-15 23:54:50 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:54:50 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:54:50 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x04192DB0>, <pipelines.DoubanPipeline object at 0x04192E30>]
2020-02-15 23:55:03 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:55:03 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:55:55 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:55:55.654245
2020-02-15 23:55:55 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0331B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0331BB90>}
2020-02-15 23:55:55 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:55:55 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:55:55 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03326070>, <pipelines.DoubanPipeline object at 0x03326150>]
2020-02-15 23:55:55 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:55:55 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:55:55.662246
2020-02-15 23:55:55 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-15 23:55:55 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:55:55 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:55:55 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:55:55 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:56:03 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:56:03.546697
2020-02-15 23:56:03 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-15 23:56:03 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:56:03 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:56:03 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-15 23:56:03 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:56:03 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:56:03.555697
2020-02-15 23:56:03 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-15 23:56:03 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:56:03 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:56:03 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:56:03 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:56:38 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:56:38.880718
2020-02-15 23:56:38 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-15 23:56:38 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:56:38 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:56:38 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316070>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-15 23:56:38 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:56:38 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:56:38.887718
2020-02-15 23:56:38 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-15 23:56:38 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:56:38 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:56:38 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:56:38 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:56:52 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:56:52.491496
2020-02-15 23:56:52 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-15 23:56:52 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:56:52 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:56:52 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316070>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-15 23:56:52 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:56:52 engine.py[line:51]                   INFO: 结束运行时间：2020-02-15 23:56:52.498496
2020-02-15 23:56:52 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:56:52 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-15 23:56:52 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-15 23:56:52 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-15 23:56:52 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-15 23:58:03 engine.py[line:44]                   INFO: 开始运行时间：2020-02-15 23:58:03.605564
2020-02-15 23:58:03 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04192D10>, 'doubai': <spiders.douban.DoubanSpider object at 0x041928B0>}
2020-02-15 23:58:03 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-15 23:58:03 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-15 23:58:03 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x04192DD0>, <pipelines.DoubanPipeline object at 0x04192E50>]
2020-02-15 23:58:06 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:58:06 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-15 23:58:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:02:10 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:02:10.964712
2020-02-16 00:02:10 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 00:02:10 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:02:10 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:02:10 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316050>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 00:02:10 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:02:10 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:02:11 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:02:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:02:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:02:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:02:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-16 00:02:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-16 00:02:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-16 00:02:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-16 00:02:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-16 00:02:12 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:02:12.391793
2020-02-16 00:02:12 engine.py[line:52]                   INFO: 耗时：1.43
2020-02-16 00:02:12 engine.py[line:53]                   INFO: 一共获取了请求：36个
2020-02-16 00:02:12 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-16 00:02:12 engine.py[line:55]                   INFO: 成功的请求：36个
2020-02-16 00:02:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-16 00:02:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-16 00:03:31 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:03:31.920342
2020-02-16 00:03:31 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:03:31 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:03:31 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:03:31 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-16 00:03:31 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:03:31 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449860/>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/678081/>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/677473/>
2020-02-16 00:03:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676947/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446906/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676930/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676650/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/676670/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446918/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/447047/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 00:03:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 00:03:34 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:03:34.937515
2020-02-16 00:03:34 engine.py[line:52]                   INFO: 耗时：3.02
2020-02-16 00:03:34 engine.py[line:53]                   INFO: 一共获取了请求：36个
2020-02-16 00:03:34 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-16 00:03:34 engine.py[line:55]                   INFO: 成功的请求：52个
2020-02-16 00:03:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 00:03:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 00:16:42 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:16:42.240546
2020-02-16 00:16:42 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B890>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BAD0>}
2020-02-16 00:16:42 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:16:42 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:16:42 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BF90>, <pipelines.DoubanPipeline object at 0x03316090>]
2020-02-16 00:16:42 scheduler.py[line:49]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:16:42 engine.py[line:128]                   ERROR: 'Scheduler' object has no attribute 'collector'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 126, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 67, in _start_request
    self.scheduler.add_request(start_request)
  File "F:\Tencent\temp\scrapy_plus\cores\scheduler.py", line 29, in add_request
    if self._filter_request(request):
  File "F:\Tencent\temp\scrapy_plus\cores\scheduler.py", line 50, in _filter_request
    self.collector.incr(self.collector.repeat_request_nums_key)
AttributeError: 'Scheduler' object has no attribute 'collector'
2020-02-16 00:16:42 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:16:45 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:16:45.241717
2020-02-16 00:16:45 engine.py[line:52]                   INFO: 耗时：3.00
2020-02-16 00:16:45 engine.py[line:53]                   INFO: 一共获取了请求：1个
2020-02-16 00:16:45 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-16 00:16:45 engine.py[line:55]                   INFO: 成功的请求：3个
2020-02-16 00:17:27 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:17:27.213118
2020-02-16 00:17:27 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8F0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB30>}
2020-02-16 00:17:27 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:17:27 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:17:27 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x033160F0>]
2020-02-16 00:17:27 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:17:27 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:17:27 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:17:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:17:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:17:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=3&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:17:29 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 00:17:29 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 00:17:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 00:17:29 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:17:29.465247
2020-02-16 00:17:29 engine.py[line:52]                   INFO: 耗时：2.25
2020-02-16 00:17:29 engine.py[line:53]                   INFO: 一共获取了请求：36个
2020-02-16 00:17:29 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:17:29 engine.py[line:55]                   INFO: 成功的请求：34个
2020-02-16 00:18:04 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:18:04.215235
2020-02-16 00:18:04 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:18:04 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:18:04 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:18:04 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03317030>, <pipelines.DoubanPipeline object at 0x03317110>]
2020-02-16 00:18:04 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:04 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:04 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:18:04.225235
2020-02-16 00:18:04 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 00:18:04 engine.py[line:53]                   INFO: 一共获取了请求：4个
2020-02-16 00:18:04 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:18:04 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 00:18:27 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:18:27.342557
2020-02-16 00:18:27 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:18:27 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:18:27 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:18:27 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-16 00:18:27 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:27 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:27 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:18:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:18:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 00:18:28 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:18:28.374616
2020-02-16 00:18:28 engine.py[line:52]                   INFO: 耗时：1.03
2020-02-16 00:18:28 engine.py[line:53]                   INFO: 一共获取了请求：14个
2020-02-16 00:18:28 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:18:28 engine.py[line:55]                   INFO: 成功的请求：12个
2020-02-16 00:18:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 00:18:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 00:18:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 00:18:54 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:18:54.595116
2020-02-16 00:18:54 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:18:54 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:18:54 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:18:54 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-16 00:18:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:54 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:18:54.612117
2020-02-16 00:18:54 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 00:18:54 engine.py[line:53]                   INFO: 一共获取了请求：4个
2020-02-16 00:18:54 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:18:54 engine.py[line:55]                   INFO: 成功的请求：3个
2020-02-16 00:18:59 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:18:59.323387
2020-02-16 00:18:59 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:18:59 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:18:59 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:18:59 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-16 00:18:59 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:59 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:18:59 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:18:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:18:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 00:18:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 00:18:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 00:18:59 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:18:59.999425
2020-02-16 00:19:00 engine.py[line:52]                   INFO: 耗时：0.68
2020-02-16 00:19:00 engine.py[line:53]                   INFO: 一共获取了请求：14个
2020-02-16 00:19:00 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:19:00 engine.py[line:55]                   INFO: 成功的请求：14个
2020-02-16 00:19:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 00:19:15 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:19:15.908335
2020-02-16 00:19:15 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:19:15 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:19:15 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:19:15 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03317030>, <pipelines.DoubanPipeline object at 0x03317110>]
2020-02-16 00:19:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:19:15 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:19:15.923336
2020-02-16 00:19:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:19:15 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 00:19:15 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 00:19:15 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:19:15 engine.py[line:55]                   INFO: 成功的请求：1个
2020-02-16 00:19:22 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:19:22.624719
2020-02-16 00:19:22 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:19:22 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:19:22 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:19:22 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-16 00:19:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:19:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:19:22 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:19:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:19:23 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:19:23 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 00:19:23 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 00:19:23 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 00:19:23 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 00:19:23 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:19:23.503770
2020-02-16 00:19:23 engine.py[line:52]                   INFO: 耗时：0.88
2020-02-16 00:19:23 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 00:19:23 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:19:23 engine.py[line:55]                   INFO: 成功的请求：25个
2020-02-16 00:19:38 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 00:19:38.732641
2020-02-16 00:19:38 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 00:19:38 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 00:19:38 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 00:19:38 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x03316110>]
2020-02-16 00:19:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:19:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 00:19:38 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 00:19:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:19:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 00:19:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 00:19:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 00:19:39 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 00:19:39.637692
2020-02-16 00:19:39 engine.py[line:52]                   INFO: 耗时：0.91
2020-02-16 00:19:39 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 00:19:39 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 00:19:39 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 00:19:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 13:14:01 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:14:01.984686
2020-02-16 13:14:01 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB10>}
2020-02-16 13:14:01 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:14:01 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:14:01 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x033160D0>]
2020-02-16 13:14:01 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:14:01.998687
2020-02-16 13:14:01 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 13:14:02 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-16 13:14:02 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-16 13:14:02 engine.py[line:55]                   INFO: 成功的请求：1个
2020-02-16 13:23:17 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:23:17.855480
2020-02-16 13:23:17 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8F0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB30>}
2020-02-16 13:23:17 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:23:17 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:23:17 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316030>, <pipelines.DoubanPipeline object at 0x033160F0>]
2020-02-16 13:23:17 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:23:17 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:23:37 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:23:37.018576
2020-02-16 13:23:37 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:23:37 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:23:37 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:23:37 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316070>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 13:23:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:23:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:23:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:23:54 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 13:23:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 13:23:58 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:24:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 13:24:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 13:24:04 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 13:24:04 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:24:04.733161
2020-02-16 13:24:04 engine.py[line:52]                   INFO: 耗时：27.71
2020-02-16 13:24:04 engine.py[line:53]                   INFO: 一共获取了请求：20个
2020-02-16 13:24:04 engine.py[line:54]                   INFO: 重复的请求：4个
2020-02-16 13:24:04 engine.py[line:55]                   INFO: 成功的请求：16个
2020-02-16 13:24:42 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:24:42.842341
2020-02-16 13:24:42 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:24:42 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:24:42 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:24:42 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316070>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 13:24:42 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:24:42 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:24:53 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:26:16 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:26:16.706710
2020-02-16 13:26:16 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 13:26:16 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:26:16 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:26:16 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316050>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 13:26:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:26:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:26:37 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:26:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:26:57 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:26:57.796060
2020-02-16 13:26:57 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0332B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0332BB90>}
2020-02-16 13:26:57 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:26:57 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:26:57 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03336070>, <pipelines.DoubanPipeline object at 0x03336150>]
2020-02-16 13:26:57 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:26:57 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:27:06 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:27:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:27:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:27:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 13:27:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 13:27:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 13:27:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 13:27:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 13:27:38 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 13:27:38 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:27:38.015360
2020-02-16 13:27:38 engine.py[line:52]                   INFO: 耗时：40.22
2020-02-16 13:27:38 engine.py[line:53]                   INFO: 一共获取了请求：45个
2020-02-16 13:27:38 engine.py[line:54]                   INFO: 重复的请求：6个
2020-02-16 13:27:38 engine.py[line:55]                   INFO: 成功的请求：39个
2020-02-16 13:30:15 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:30:15.921392
2020-02-16 13:30:15 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:30:15 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:30:15 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:30:15 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316070>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 13:30:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:30:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:30:17 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:30:19 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:30:22 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:30:26 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 13:30:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 13:30:27 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:30:27.532056
2020-02-16 13:30:27 engine.py[line:52]                   INFO: 耗时：11.61
2020-02-16 13:30:27 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 13:30:27 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:30:27 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 13:30:46 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:30:46.729154
2020-02-16 13:30:46 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:30:46 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:30:46 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:30:46 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316070>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 13:30:46 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:30:46 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:30:47 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:30:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:30:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 13:30:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 13:30:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 13:30:53 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:30:53.132520
2020-02-16 13:30:53 engine.py[line:52]                   INFO: 耗时：6.40
2020-02-16 13:30:53 engine.py[line:53]                   INFO: 一共获取了请求：15个
2020-02-16 13:30:53 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:30:53 engine.py[line:55]                   INFO: 成功的请求：14个
2020-02-16 13:32:50 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:32:50.647242
2020-02-16 13:32:50 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04191CD0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04191870>}
2020-02-16 13:32:50 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:32:50 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:32:50 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x04191E10>, <pipelines.DoubanPipeline object at 0x04191E30>]
2020-02-16 13:32:53 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:32:53 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:32:58 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:33:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:33:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 13:33:06 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 13:33:06 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:33:06.322138
2020-02-16 13:33:06 engine.py[line:52]                   INFO: 耗时：15.67
2020-02-16 13:33:06 engine.py[line:53]                   INFO: 一共获取了请求：15个
2020-02-16 13:33:06 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:33:06 engine.py[line:55]                   INFO: 成功的请求：13个
2020-02-16 13:34:01 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:34:01.116272
2020-02-16 13:34:01 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:34:01 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:34:01 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:34:01 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03317150>, <pipelines.DoubanPipeline object at 0x03317170>]
2020-02-16 13:34:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:34:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:34:01 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:34:01.137274
2020-02-16 13:34:01 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 13:34:01 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 13:34:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:34:01 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 13:34:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:34:01 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:34:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:34:26 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:34:26.348716
2020-02-16 13:34:26 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:34:26 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:34:26 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:34:26 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:34:26 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:34:26 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:34:26 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:34:26 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:34:26 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:34:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 13:34:27 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:34:27.383775
2020-02-16 13:34:27 engine.py[line:52]                   INFO: 耗时：1.04
2020-02-16 13:34:27 engine.py[line:53]                   INFO: 一共获取了请求：7个
2020-02-16 13:34:27 engine.py[line:54]                   INFO: 重复的请求：6个
2020-02-16 13:34:27 engine.py[line:55]                   INFO: 成功的请求：1个
2020-02-16 13:42:08 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:42:08.464147
2020-02-16 13:42:08 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0333B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0333BB90>}
2020-02-16 13:42:08 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:42:08 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:42:08 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03346150>, <pipelines.DoubanPipeline object at 0x03346170>]
2020-02-16 13:42:11 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:42:11 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:42:11 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:42:11.527322
2020-02-16 13:42:11 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:42:11 engine.py[line:52]                   INFO: 耗时：3.06
2020-02-16 13:42:11 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 13:42:11 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 13:42:11 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:42:11 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:42:11 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:46:54 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:46:54.714520
2020-02-16 13:46:54 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:46:54 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:46:54 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:46:54 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:46:54 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:46:54.732521
2020-02-16 13:46:54 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 13:46:54 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 13:46:54 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:46:54 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:47:09 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:47:09.096342
2020-02-16 13:47:09 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 13:47:09 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:47:09 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:47:09 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316110>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 13:47:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:47:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:47:09 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:47:09.109343
2020-02-16 13:47:09 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 13:47:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:47:09 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 13:47:09 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 13:47:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:47:09 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:47:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:50:51 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:50:51.241048
2020-02-16 13:50:51 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:50:51 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:50:51 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:50:51 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:50:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:50:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:50:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:50:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:50:54 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:51:59 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:51:59.738966
2020-02-16 13:51:59 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:51:59 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:51:59 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:51:59 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:51:59 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:51:59 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:00 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:52:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:52:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 13:52:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 13:52:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 13:52:02 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:52:02.939149
2020-02-16 13:52:02 engine.py[line:52]                   INFO: 耗时：3.20
2020-02-16 13:52:02 engine.py[line:53]                   INFO: 一共获取了请求：15个
2020-02-16 13:52:02 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:52:02 engine.py[line:55]                   INFO: 成功的请求：14个
2020-02-16 13:52:29 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:52:29.004640
2020-02-16 13:52:29 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:52:29 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:52:29 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:52:29 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:52:29 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:29 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:29 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:29 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:52:29.032642
2020-02-16 13:52:29 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 13:52:29 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:52:29 engine.py[line:53]                   INFO: 一共获取了请求：3个
2020-02-16 13:52:29 engine.py[line:54]                   INFO: 重复的请求：4个
2020-02-16 13:52:29 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:52:29 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:52:32 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:52:32.892862
2020-02-16 13:52:32 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:52:32 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:52:32 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:52:32 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:52:32 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:32 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:32 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:32 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:52:32 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:52:32.914864
2020-02-16 13:52:32 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 13:52:32 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:52:32 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 13:52:32 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 13:52:32 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:52:34 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:52:34.887976
2020-02-16 13:52:34 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:52:34 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:52:34 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:52:34 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:52:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:34 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:52:34.899977
2020-02-16 13:52:34 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 13:52:34 engine.py[line:53]                   INFO: 一共获取了请求：1个
2020-02-16 13:52:34 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:52:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:34 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:52:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:52:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:52:37 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:52:37.214110
2020-02-16 13:52:37 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 13:52:37 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:52:37 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:52:37 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316110>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 13:52:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:37 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:52:37.223110
2020-02-16 13:52:37 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 13:52:37 engine.py[line:53]                   INFO: 一共获取了请求：3个
2020-02-16 13:52:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:37 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 13:52:37 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:52:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:52:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:52:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:54:33 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:54:33.549764
2020-02-16 13:54:33 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F3BF90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F5C0D0>}
2020-02-16 13:54:33 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:54:33 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:54:33 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F5C690>, <pipelines.DoubanPipeline object at 0x03F5C6B0>]
2020-02-16 13:54:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:33 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:54:33.582765
2020-02-16 13:54:33 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 13:54:33 engine.py[line:53]                   INFO: 一共获取了请求：3个
2020-02-16 13:54:33 engine.py[line:54]                   INFO: 重复的请求：4个
2020-02-16 13:54:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:33 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:54:37 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:54:37.619996
2020-02-16 13:54:37 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03988EB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03988FD0>}
2020-02-16 13:54:37 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:54:37 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:54:37 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x039A95B0>, <pipelines.DoubanPipeline object at 0x039A95D0>]
2020-02-16 13:54:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:54:37 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:54:58 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:54:58.449188
2020-02-16 13:54:58 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F48EF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F48FF0>}
2020-02-16 13:54:58 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:54:58 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:54:58 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F695F0>, <pipelines.DoubanPipeline object at 0x03F69610>]
2020-02-16 13:54:58 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:58 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:58 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:54:58 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:54:58 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:55:06 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:55:06.615655
2020-02-16 13:55:06 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F48EF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F48FF0>}
2020-02-16 13:55:06 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:55:06 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:55:06 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F695F0>, <pipelines.DoubanPipeline object at 0x03F69610>]
2020-02-16 13:55:06 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:55:06 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:55:06 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:55:06 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:55:06 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:55:15 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:55:15.425159
2020-02-16 13:55:15 engine.py[line:52]                   INFO: 耗时：8.81
2020-02-16 13:55:15 engine.py[line:53]                   INFO: 一共获取了请求：0个
2020-02-16 13:55:15 engine.py[line:54]                   INFO: 重复的请求：0个
2020-02-16 13:55:15 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:55:21 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:55:21.971533
2020-02-16 13:55:21 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F48EF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F48FF0>}
2020-02-16 13:55:21 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:55:21 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:55:21 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F695F0>, <pipelines.DoubanPipeline object at 0x03F69610>]
2020-02-16 13:55:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:55:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:55:24 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:56:38 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:56:38.168891
2020-02-16 13:56:38 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F18EF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F18FF0>}
2020-02-16 13:56:38 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:56:38 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:56:38 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F395F0>, <pipelines.DoubanPipeline object at 0x03F39610>]
2020-02-16 13:56:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:56:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:56:38 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 13:56:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:56:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 13:56:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 13:56:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 13:56:39 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:56:39.247953
2020-02-16 13:56:39 engine.py[line:52]                   INFO: 耗时：1.08
2020-02-16 13:56:39 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 13:56:39 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:56:39 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 13:56:56 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:56:56.802957
2020-02-16 13:56:56 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F28EF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F28FF0>}
2020-02-16 13:56:56 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:56:56 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:56:56 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F495F0>, <pipelines.DoubanPipeline object at 0x03F49610>]
2020-02-16 13:56:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:56:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:56:56 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:56:56.851960
2020-02-16 13:56:56 engine.py[line:52]                   INFO: 耗时：0.05
2020-02-16 13:56:56 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 13:56:56 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 13:56:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:56:56 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:57:24 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:57:24.687552
2020-02-16 13:57:24 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F5BF90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F7C0D0>}
2020-02-16 13:57:24 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:57:24 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:57:24 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03F7C690>, <pipelines.DoubanPipeline object at 0x03F7C6B0>]
2020-02-16 13:57:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:57:24 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:57:24.739555
2020-02-16 13:57:24 engine.py[line:52]                   INFO: 耗时：0.05
2020-02-16 13:57:24 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 13:57:24 engine.py[line:54]                   INFO: 重复的请求：4个
2020-02-16 13:57:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:57:24 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:57:41 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:57:41.720526
2020-02-16 13:57:41 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 13:57:41 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:57:41 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:57:41 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03317110>, <pipelines.DoubanPipeline object at 0x03317130>]
2020-02-16 13:57:41 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:41 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:41 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:41 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:57:41.735527
2020-02-16 13:57:41 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 13:57:41 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 13:57:41 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 13:57:41 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 13:57:41 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:57:41 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:57:49 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 13:57:49.660980
2020-02-16 13:57:49 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 13:57:49 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 13:57:49 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 13:57:49 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 13:57:49 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:49 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:49 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 13:57:49 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 13:57:49 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 13:57:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 13:57:50 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 13:57:50.123007
2020-02-16 13:57:50 engine.py[line:52]                   INFO: 耗时：0.46
2020-02-16 13:57:50 engine.py[line:53]                   INFO: 一共获取了请求：7个
2020-02-16 13:57:50 engine.py[line:54]                   INFO: 重复的请求：6个
2020-02-16 13:57:50 engine.py[line:55]                   INFO: 成功的请求：1个
2020-02-16 14:00:41 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:00:41.787826
2020-02-16 14:00:41 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:00:41.787826
2020-02-16 14:00:41 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:00:41 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:00:41 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:00:41 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:00:41 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316130>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:00:44 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:00:44.800998
2020-02-16 14:00:44 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:00:44 engine.py[line:53]                   INFO: 一共获取了请求：3个
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:00:44 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:00:44 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:00:44 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:00:44.813999
2020-02-16 14:00:44 engine.py[line:52]                   INFO: 耗时：3.03
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:00:44 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:00:44 engine.py[line:53]                   INFO: 一共获取了请求：1个
2020-02-16 14:00:44 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 14:00:44 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:07:53 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:07:53.001490
2020-02-16 14:07:53 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:07:53 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:07:53 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:07:53 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:07:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:07:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:07:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:07:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:07:56 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:07:56.013662
2020-02-16 14:07:56 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-16 14:07:56 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:07:56 engine.py[line:53]                   INFO: 一共获取了请求：4个
2020-02-16 14:07:56 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:07:56 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:14:12 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:14:12.848216
2020-02-16 14:14:12 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:14:12 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:14:12 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:14:12 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316130>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 14:14:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 14:14:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 14:14:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 14:14:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 14:14:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:14:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:14:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:14:15 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:14:15.851387
2020-02-16 14:14:15 engine.py[line:52]                   INFO: 耗时：3.00
2020-02-16 14:14:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:14:15 engine.py[line:53]                   INFO: 一共获取了请求：3个
2020-02-16 14:14:15 engine.py[line:54]                   INFO: 重复的请求：4个
2020-02-16 14:14:15 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:14:15 engine.py[line:55]                   INFO: 成功的请求：4个
2020-02-16 14:15:09 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:15:09.392450
2020-02-16 14:15:09 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:15:09 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:15:09 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:15:09 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:15:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:15:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:15:09 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:15:09.401450
2020-02-16 14:15:09 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 14:15:09 engine.py[line:53]                   INFO: 一共获取了请求：1个
2020-02-16 14:15:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:15:09 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 14:15:09 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:15:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:15:09 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:16:58 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:16:58.118668
2020-02-16 14:16:58 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:16:58 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:16:58 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:16:58 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:17:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:17:01 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:17:01.123840
2020-02-16 14:17:01 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-16 14:17:01 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 14:17:01 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 14:17:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:17:01 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:17:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:17:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:17:01 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:18:03 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:18:03.452405
2020-02-16 14:18:03 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:18:03 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:18:03 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:18:03 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:18:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:06 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 14:18:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:18:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:18:08 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 14:18:08 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 14:18:08 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 14:18:09 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 14:18:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 14:18:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 14:18:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 14:18:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 14:18:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 14:18:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 14:18:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 14:18:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 14:18:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 14:18:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 14:18:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 14:18:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 14:18:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 14:18:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 14:18:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 14:18:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 14:18:14 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:18:14.662046
2020-02-16 14:18:14 engine.py[line:52]                   INFO: 耗时：11.21
2020-02-16 14:18:14 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 14:18:14 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 14:18:14 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 14:18:20 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:18:20.101358
2020-02-16 14:18:20 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:18:20 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:18:20 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:18:20 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:18:20 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:20 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:20 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:18:20.109358
2020-02-16 14:18:20 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:20 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 14:18:20 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 14:18:20 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 14:18:20 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:18:20 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:18:20 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:18:24 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:18:24.358601
2020-02-16 14:18:24 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:18:24 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:18:24 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:18:24 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:18:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:18:24 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:18:48 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:18:48.303971
2020-02-16 14:18:48 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:18:48 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:18:48 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:18:48 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:18:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:18:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:18:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:21:18 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:21:18.726574
2020-02-16 14:21:18 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:21:18 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:21:18 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:21:18 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316130>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 14:21:21 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:21:21 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:21:21 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:21:21 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:21:21 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:22:35 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:22:35.521967
2020-02-16 14:22:35 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 14:22:35 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:22:35 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:22:35 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316110>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 14:22:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:22:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:22:39 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:22:39.754209
2020-02-16 14:22:39 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 14:22:39 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:22:39 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:22:39 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316110>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 14:22:39 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:39 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:39 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:39 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:22:39 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:22:51 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:22:51.028854
2020-02-16 14:22:51 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:22:51 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:22:51 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:22:51 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:22:51 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:51 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:22:51 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 14:22:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:22:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:22:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 14:22:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 14:22:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 14:22:53 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 14:22:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 14:22:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 14:22:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 14:22:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 14:22:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 14:22:55 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 14:22:56 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 14:22:56 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 14:22:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 14:22:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 14:22:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 14:22:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 14:22:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 14:22:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/449803/>
2020-02-16 14:22:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 14:22:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 14:22:59 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:22:59.410333
2020-02-16 14:22:59 engine.py[line:52]                   INFO: 耗时：8.38
2020-02-16 14:22:59 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 14:22:59 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 14:22:59 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 14:23:16 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:23:16.919335
2020-02-16 14:23:16 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:23:16 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:23:16 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:23:16 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:23:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:23:16 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:23:16 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:23:16.936336
2020-02-16 14:23:16 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:23:16 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:23:16 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:23:16 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:23:22 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:23:22.501654
2020-02-16 14:23:22 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:23:22 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:23:22 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:23:22 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:23:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:23:22 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:23:22 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:23:22.518655
2020-02-16 14:23:22 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:23:22 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:23:22 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:23:22 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:23:35 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:23:35.978425
2020-02-16 14:23:35 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:23:35 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:23:35 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:23:35 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:23:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:23:35 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:23:35 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:23:35.998426
2020-02-16 14:23:35 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:23:35 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:23:35 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:23:36 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:23:38 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:23:38.528571
2020-02-16 14:23:38 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:23:38 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:23:38 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:23:38 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316150>, <pipelines.DoubanPipeline object at 0x03316170>]
2020-02-16 14:23:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:23:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:23:38 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:23:38 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:23:38.543571
2020-02-16 14:23:38 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 14:23:38 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:23:38 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:23:38 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:25:45 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:25:45.822851
2020-02-16 14:25:45 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:25:45 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:25:45 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:25:45 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316130>, <pipelines.DoubanPipeline object at 0x03316150>]
2020-02-16 14:25:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:25:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:25:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:25:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:25:48 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:25:48 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:25:48.848024
2020-02-16 14:25:48 engine.py[line:52]                   INFO: 耗时：3.03
2020-02-16 14:25:48 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:25:48 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:25:48 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:26:45 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:26:45.198247
2020-02-16 14:26:45 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 14:26:45 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:26:45 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:26:45 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x03316110>, <pipelines.DoubanPipeline object at 0x03316130>]
2020-02-16 14:26:45 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:26:45 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:26:45 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:26:45 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:26:45 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:26:45 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:26:45.261251
2020-02-16 14:26:45 engine.py[line:52]                   INFO: 耗时：0.06
2020-02-16 14:26:45 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:26:45 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:26:45 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:32:26 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:32:26.992797
2020-02-16 14:32:26 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:32:26 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:32:26 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:32:26 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE50>, <pipelines.DoubanPipeline object at 0x0330BFF0>]
2020-02-16 14:32:29 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:32:30 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:32:30 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:32:30 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:32:30 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:32:30 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:32:30.006969
2020-02-16 14:32:30 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-16 14:32:30 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:32:30 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:32:30 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:32:33 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:32:33.742183
2020-02-16 14:32:33 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:32:33 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:32:33 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:32:33 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:32:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:32:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:32:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:32:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:32:33 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:32:33 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:32:33.760184
2020-02-16 14:32:33 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:32:33 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:32:33 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:32:33 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:33:00 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:33:00.902737
2020-02-16 14:33:00 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 14:33:00 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:33:00 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:33:00 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE30>, <pipelines.DoubanPipeline object at 0x0330BFD0>]
2020-02-16 14:33:00 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:00 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:00 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:00 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:33:00 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:33:00 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:33:00.920738
2020-02-16 14:33:00 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:33:00 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:33:00 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:33:00 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:33:03 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:33:03.864906
2020-02-16 14:33:03 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0334B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0334BB90>}
2020-02-16 14:33:03 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:33:03 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:33:03 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0334BE70>, <pipelines.DoubanPipeline object at 0x0332D030>]
2020-02-16 14:33:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:33:03 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:33:03 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:33:03.881907
2020-02-16 14:33:03 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:33:03 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:33:03 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:33:03 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:33:05 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:33:05.807017
2020-02-16 14:33:05 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0333B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0333BB90>}
2020-02-16 14:33:05 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:33:05 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:33:05 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0333BE70>, <pipelines.DoubanPipeline object at 0x0331D030>]
2020-02-16 14:33:05 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:05 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:05 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:33:05 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:33:05 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:33:05 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:33:05.824018
2020-02-16 14:33:05 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:33:05 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:33:05 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:33:05 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:38:14 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:38:14.329664
2020-02-16 14:38:14 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:38:14 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:38:14 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:38:14 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:38:14 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:38:14 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:38:14 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:38:14 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:38:14 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:38:17 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:38:17.335835
2020-02-16 14:38:17 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-16 14:38:17 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:38:17 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:38:17 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:38:34 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:38:34.909841
2020-02-16 14:38:34 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:38:34 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:38:34 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:38:34 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x03316030>]
2020-02-16 14:38:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:38:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:38:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:38:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:38:34 scheduler.py[line:50]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:38:34 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:38:34.952843
2020-02-16 14:38:34 engine.py[line:52]                   INFO: 耗时：0.04
2020-02-16 14:38:34 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:38:34 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:38:34 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:39:14 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:39:14.451102
2020-02-16 14:39:14 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB10>}
2020-02-16 14:39:14 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:39:14 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:39:14 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BDF0>, <pipelines.DoubanPipeline object at 0x0330BF90>]
2020-02-16 14:39:14 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:14 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:14 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:14 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:39:14 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:39:14 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:39:14.527107
2020-02-16 14:39:14 engine.py[line:52]                   INFO: 耗时：0.08
2020-02-16 14:39:14 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:39:14 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:39:14 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:39:25 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:39:25.658743
2020-02-16 14:39:25 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 14:39:25 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:39:25 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:39:25 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE30>, <pipelines.DoubanPipeline object at 0x0330BFD0>]
2020-02-16 14:39:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:39:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:39:25 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:39:25.690745
2020-02-16 14:39:25 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 14:39:25 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:39:25 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:39:25 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:39:58 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:39:58.808639
2020-02-16 14:39:58 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 14:39:58 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:39:58 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:39:58 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE30>, <pipelines.DoubanPipeline object at 0x0330BFD0>]
2020-02-16 14:39:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:39:59 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 14:39:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:39:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 14:40:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 14:40:01 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 14:40:01 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:40:01.665803
2020-02-16 14:40:01 engine.py[line:52]                   INFO: 耗时：2.86
2020-02-16 14:40:01 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 14:40:01 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 14:40:01 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 14:40:19 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:40:19.239808
2020-02-16 14:40:19 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:40:19 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:40:19 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:40:19 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:40:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:40:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:40:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:40:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:40:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:40:19 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:40:19.266810
2020-02-16 14:40:19 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 14:40:19 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:40:19 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:40:19 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:41:22 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:41:22.406421
2020-02-16 14:41:22 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:41:22 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:41:22 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:41:22 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE50>, <pipelines.DoubanPipeline object at 0x0330BFF0>]
2020-02-16 14:41:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:41:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:41:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:41:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:41:25 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:41:25 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:41:25.427594
2020-02-16 14:41:25 engine.py[line:52]                   INFO: 耗时：3.02
2020-02-16 14:41:25 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:41:25 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:41:25 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:44:52 engine.py[line:44]                   INFO: 开始运行时间：2020-02-16 14:44:52.615444
2020-02-16 14:44:52 engine.py[line:45]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:44:52 engine.py[line:46]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:44:52 engine.py[line:47]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:44:52 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE50>, <pipelines.DoubanPipeline object at 0x0330BFF0>]
2020-02-16 14:44:55 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:44:55 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:44:55 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:44:55 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:44:55 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:44:55 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:44:55.627616
2020-02-16 14:44:55 engine.py[line:52]                   INFO: 耗时：3.01
2020-02-16 14:44:55 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:44:55 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:44:55 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:45:13 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:45:13.636647
2020-02-16 14:45:13 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:45:13 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:45:13 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:45:13 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE50>, <pipelines.DoubanPipeline object at 0x0330BFF0>]
2020-02-16 14:45:13 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:45:13 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:45:13 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:45:13 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:45:13 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:45:13 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:45:13.654648
2020-02-16 14:45:13 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:45:13 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:45:13 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:45:13 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:45:17 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:45:17.126846
2020-02-16 14:45:17 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:45:17 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:45:17 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:45:17 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:45:17 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:45:17 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:45:17 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:45:17 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:45:17 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:45:17 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:45:17.142847
2020-02-16 14:45:17 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 14:45:17 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:45:17 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:45:17 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:48:22 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:48:22.520450
2020-02-16 14:48:22 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04162CB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04162850>}
2020-02-16 14:48:22 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:48:22 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:48:22 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x04162C70>, <pipelines.DoubanPipeline object at 0x04162CD0>]
2020-02-16 14:48:32 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:48:32 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:48:32.281008
2020-02-16 14:48:32 engine.py[line:52]                   INFO: 耗时：9.76
2020-02-16 14:48:32 engine.py[line:53]                   INFO: 一共获取了请求：1个
2020-02-16 14:48:32 engine.py[line:54]                   INFO: 重复的请求：1个
2020-02-16 14:48:32 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:48:49 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:48:49.791010
2020-02-16 14:48:49 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x041A2CB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x041A2850>}
2020-02-16 14:48:49 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:48:49 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:48:49 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x041A2C70>, <pipelines.DoubanPipeline object at 0x041A2CD0>]
2020-02-16 14:49:13 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:49:13 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:49:13.083342
2020-02-16 14:49:13 engine.py[line:52]                   INFO: 耗时：23.29
2020-02-16 14:49:13 engine.py[line:53]                   INFO: 一共获取了请求：1个
2020-02-16 14:49:13 engine.py[line:54]                   INFO: 重复的请求：1个
2020-02-16 14:49:13 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:49:29 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:49:29.005253
2020-02-16 14:49:29 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 14:49:29 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:49:29 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:49:29 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE50>, <pipelines.DoubanPipeline object at 0x0330BFF0>]
2020-02-16 14:49:29 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:49:29 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:49:29 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:49:29 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:49:29 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:49:29 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:49:29.031254
2020-02-16 14:49:29 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 14:49:29 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:49:29 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:49:29 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 14:56:42 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:56:42.150027
2020-02-16 14:56:42 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:56:42 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:56:42 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:56:42 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:56:45 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:56:45 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:56:45 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 14:56:52 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:56:52.932644
2020-02-16 14:56:52 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:56:52 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:56:52 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:56:52 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:56:52 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:56:52 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:56:52 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:56:52 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:56:52 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:57:19 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:57:19.274151
2020-02-16 14:57:19 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:57:19 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:57:19 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:57:19 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:57:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:57:19 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:57:32 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:57:32.760922
2020-02-16 14:57:32 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:57:32 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:57:32 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:57:32 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:57:32 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:32 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:32 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 14:57:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 14:57:34 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 14:57:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 14:57:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 14:57:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 14:57:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 14:57:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 14:57:35 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 14:57:35 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:57:35.604085
2020-02-16 14:57:35 engine.py[line:52]                   INFO: 耗时：2.84
2020-02-16 14:57:35 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 14:57:35 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 14:57:35 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 14:57:42 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 14:57:42.193462
2020-02-16 14:57:42 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 14:57:42 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 14:57:42 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 14:57:42 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 14:57:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 14:57:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 14:57:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 14:57:42 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 14:57:42.220463
2020-02-16 14:57:42 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 14:57:42 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 14:57:42 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 14:57:42 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:00:40 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:00:40.161641
2020-02-16 15:00:40 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B8F0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB30>}
2020-02-16 15:00:40 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:00:40 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:00:40 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE10>, <pipelines.DoubanPipeline object at 0x0330BFB0>]
2020-02-16 15:00:40 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:40 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:40 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:40 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:00:40 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:00:40 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:00:40.188642
2020-02-16 15:00:40 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 15:00:40 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 15:00:40 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 15:00:40 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:00:44 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:00:44.512890
2020-02-16 15:00:44 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:00:44 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:00:44 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:00:44 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:00:44 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:44 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:44 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:44 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:00:44 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:00:44 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:00:44.539891
2020-02-16 15:00:44 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 15:00:44 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 15:00:44 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 15:00:44 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:00:53 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:00:53.816422
2020-02-16 15:00:53 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B910>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB50>}
2020-02-16 15:00:53 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:00:53 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:00:53 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE30>, <pipelines.DoubanPipeline object at 0x0330BFD0>]
2020-02-16 15:00:53 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:53 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:53 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:53 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:00:53 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:00:53 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:00:53.863424
2020-02-16 15:00:53 engine.py[line:52]                   INFO: 耗时：0.05
2020-02-16 15:00:53 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 15:00:53 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 15:00:53 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:00:58 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:00:58.276677
2020-02-16 15:00:58 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:00:58 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:00:58 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:00:58 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:00:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:00:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:00:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:00:58 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:00:58.305679
2020-02-16 15:00:58 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 15:00:58 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 15:00:58 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 15:00:58 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:02:39 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:02:39.677477
2020-02-16 15:02:39 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0331B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0331BB70>}
2020-02-16 15:02:39 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:02:39 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:02:39 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0331BE50>, <pipelines.DoubanPipeline object at 0x0331BFF0>]
2020-02-16 15:02:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:02:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:02:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:02:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:02:42 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:03:34 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:03:34.322602
2020-02-16 15:03:34 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B930>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB70>}
2020-02-16 15:03:34 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:03:34 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:03:34 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE50>, <pipelines.DoubanPipeline object at 0x0330BFF0>]
2020-02-16 15:03:34 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:34 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:34 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:34 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:03:34 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:03:34 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:03:34.347604
2020-02-16 15:03:34 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 15:03:34 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 15:03:34 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 15:03:34 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:03:43 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:03:43.637135
2020-02-16 15:03:43 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:03:43 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:03:43 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:03:43 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:03:43 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:43 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:43 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:43 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:03:43 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:03:43 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:03:43.662136
2020-02-16 15:03:43 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 15:03:43 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 15:03:43 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 15:03:43 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:03:46 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:03:46.388292
2020-02-16 15:03:46 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:03:46 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:03:46 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:03:46 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:03:46 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:46 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:03:46.402293
2020-02-16 15:03:46 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 15:03:46 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:46 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 15:03:46 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:46 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 15:03:46 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:03:46 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:03:46 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:03:54 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:03:54.488756
2020-02-16 15:03:54 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:03:54 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:03:54 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:03:54 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:03:54 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:54 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:03:54.499756
2020-02-16 15:03:54 engine.py[line:52]                   INFO: 耗时：0.01
2020-02-16 15:03:54 engine.py[line:53]                   INFO: 一共获取了请求：2个
2020-02-16 15:03:54 engine.py[line:54]                   INFO: 重复的请求：3个
2020-02-16 15:03:54 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:54 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:03:54 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:54 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:03:54 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:03:58 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:03:58.717998
2020-02-16 15:03:58 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:03:58 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:03:58 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:03:58 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:03:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:03:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 15:03:58 scheduler.py[line:51]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 15:03:58 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:03:58.745999
2020-02-16 15:03:58 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 15:03:58 engine.py[line:53]                   INFO: 一共获取了请求：8个
2020-02-16 15:03:58 engine.py[line:54]                   INFO: 重复的请求：8个
2020-02-16 15:03:58 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 15:05:06 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 15:05:06.161855
2020-02-16 15:05:06 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330B950>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330BB90>}
2020-02-16 15:05:06 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 15:05:06 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 15:05:06 engine.py[line:48]                   INFO: 启用的管道有：[<pipelines.BaiduPipeline object at 0x0330BE70>, <pipelines.DoubanPipeline object at 0x032CD030>]
2020-02-16 15:05:09 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:05:09 scheduler.py[line:51]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 15:05:09 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 15:05:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 15:05:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 15:05:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 15:05:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 15:05:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 15:05:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 15:05:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 15:05:12 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 15:05:12.307207
2020-02-16 15:05:12 engine.py[line:52]                   INFO: 耗时：6.15
2020-02-16 15:05:12 engine.py[line:53]                   INFO: 一共获取了请求：25个
2020-02-16 15:05:12 engine.py[line:54]                   INFO: 重复的请求：2个
2020-02-16 15:05:12 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 16:01:31 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:01:31.542488
2020-02-16 16:01:31 engine.py[line:44]                   INFO: 运行的爬虫有：{'sina_gundong': <spiders.sina.SinaGunDong object at 0x03307BD0>}
2020-02-16 16:01:31 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:01:31 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:01:31 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:01:31 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:01:41 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:01:51 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:04:04 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:04:04.039210
2020-02-16 16:04:04 engine.py[line:44]                   INFO: 运行的爬虫有：{'sina_gundong': <spiders.sina.SinaGunDong object at 0x03347BF0>}
2020-02-16 16:04:04 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:04:04 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:04:04 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:04:04 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:04:19 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:04:19.786111
2020-02-16 16:04:19 engine.py[line:44]                   INFO: 运行的爬虫有：{'sina_gundong': <spiders.sina.SinaGunDong object at 0x03307BF0>}
2020-02-16 16:04:19 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:04:19 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:04:19 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:04:19 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:04:29 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:18:24 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:18:24.630433
2020-02-16 16:18:24 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C70>, 'sina_gundong': <spiders.sina.SinaGunDong object at 0x03307F70>}
2020-02-16 16:18:24 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:18:24 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:18:24 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:18:24 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:24 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:24 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:24 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:18:24 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:18:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:18:28 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:18:28 engine.py[line:136]                   ERROR: 'NoneType' object has no attribute 'list'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 95, in _execute_request_response_item
    for result in parse(response):
  File "F:\Tencent\project\spiders\sina.py", line 26, in parse
    yield Item(ret.list).data
AttributeError: 'NoneType' object has no attribute 'list'
2020-02-16 16:18:28 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:18:28 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:18:34 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:18:37 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:05 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:19:05.256757
2020-02-16 16:19:05 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C30>}
2020-02-16 16:19:05 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:19:05 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:19:05 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:19:05 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:05 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:05 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:05 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:05 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:19:05 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:19:05 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:19:05 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:05 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:19:05 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:05 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:19:46 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:19:46.787132
2020-02-16 16:19:46 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C30>}
2020-02-16 16:19:46 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:19:46 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:19:46 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:19:46 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:19:47 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:47 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:19:47 downloader.py[line:19]                   INFO: <204 http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=&k=&offset_page=0&offset_num=0&num=120&asc=&page=1&r=0.5559616678192825>
2020-02-16 16:19:47 engine.py[line:136]                   ERROR: 'sina_gundong'
Traceback (most recent call last):
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 134, in _error_callback
    raise exception  # 抛出异常后，才能被日志进行完整记录下来
  File "c:\users\administrator\appdata\local\programs\python\python36-32\Lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "F:\Tencent\temp\scrapy_plus\cores\engine.py", line 93, in _execute_request_response_item
    spider = self.spiders[request.spider_name]
KeyError: 'sina_gundong'
2020-02-16 16:20:57 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:20:57.018149
2020-02-16 16:20:57 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C70>}
2020-02-16 16:20:57 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:20:57 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:20:57 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/456004/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/456014/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455997/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455998/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//post/819165/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//question/686763/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//post/819114/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455095/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455011/>
2020-02-16 16:20:57 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455847/>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 16:20:57 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 16:20:58 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 16:20:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 16:20:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 16:20:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 16:20:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 16:20:59 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 16:21:27 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:21:27.594898
2020-02-16 16:21:27 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C70>}
2020-02-16 16:21:27 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:21:27 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:21:27 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:27 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:51 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:21:51.485265
2020-02-16 16:21:51 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C70>}
2020-02-16 16:21:51 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:21:51 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:21:51 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:21:51 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:27:48 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:27:48.173666
2020-02-16 16:27:48 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C70>}
2020-02-16 16:27:48 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:27:48 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:27:48 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:27:48 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 16:27:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:27:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:27:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/456004/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/456014/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455997/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455998/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//post/819165/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//question/686763/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//post/819114/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455095/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455011/>
2020-02-16 16:27:48 scheduler.py[line:55]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455847/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 16:27:49 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 16:27:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 16:27:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 16:27:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 16:27:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 16:27:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 16:27:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 16:27:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 16:27:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 16:27:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 16:27:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 16:27:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 16:31:19 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:31:19.627760
2020-02-16 16:31:19 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C30>}
2020-02-16 16:31:19 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:31:19 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:31:19 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:41 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:31:41.967038
2020-02-16 16:31:41 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C70>}
2020-02-16 16:31:41 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:31:41 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:31:41 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:31:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:31:42 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 16:31:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:31:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:31:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/456004/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/456014/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455997/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455998/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//post/819165/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//question/686763/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//post/819114/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455095/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455011/>
2020-02-16 16:31:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455847/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455653/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//question/686212/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//question/684986/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/455318/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//post/818751/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/449701/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//post/818716/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/449803/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/446357/>
2020-02-16 16:31:42 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com//article/449842/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 16:31:43 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 16:31:44 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 16:33:25 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:33:25.583965
2020-02-16 16:33:25 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:33:25 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:33:25 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:33:25 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:33:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:33:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:33:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:25 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 16:33:25 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 16:33:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:33:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:33:26 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 16:33:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 16:33:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 16:33:26 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 16:33:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 16:33:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 16:33:28 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:33:28.510132
2020-02-16 16:33:28 engine.py[line:52]                   INFO: 耗时：2.93
2020-02-16 16:33:28 engine.py[line:53]                   INFO: 一共获取了请求：30个
2020-02-16 16:33:28 engine.py[line:54]                   INFO: 重复的请求：6个
2020-02-16 16:33:28 engine.py[line:55]                   INFO: 成功的请求：24个
2020-02-16 16:33:55 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:33:55.272663
2020-02-16 16:33:55 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:33:55 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:33:55 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:33:55 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:33:55 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:33:55.294664
2020-02-16 16:33:55 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 16:33:55 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:33:55 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:33:55 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:35:09 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:35:08.667861
2020-02-16 16:35:10 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04191DD0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04191930>}
2020-02-16 16:35:10 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:35:13 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:35:14 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:36:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:20 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:22 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:22 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:22 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:25 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:25 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:37:25.159668
2020-02-16 16:37:25 engine.py[line:52]                   INFO: 耗时：136.49
2020-02-16 16:37:25 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:37:25 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:37:25 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:37:31 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:37:31.344021
2020-02-16 16:37:31 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:37:31 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:37:31 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:37:31 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:31 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:37:31.366023
2020-02-16 16:37:31 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 16:37:31 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:37:31 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:37:31 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:37:33 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:37:33.256131
2020-02-16 16:37:33 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:37:33 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:37:33 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:37:33 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:33 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:37:33.277132
2020-02-16 16:37:33 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 16:37:33 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:37:33 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:37:33 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:37:35 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:37:35.106237
2020-02-16 16:37:35 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC30>}
2020-02-16 16:37:35 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:37:35 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:37:35 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:35 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:37:35.132238
2020-02-16 16:37:35 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 16:37:35 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:37:35 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:37:35 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:37:36 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:37:36.926341
2020-02-16 16:37:36 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC30>}
2020-02-16 16:37:36 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:37:36 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:37:36 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:36 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:36 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:37:36.949342
2020-02-16 16:37:36 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 16:37:36 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:37:36 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:37:36 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:37:41 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:37:41.728615
2020-02-16 16:37:41 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:37:41 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:37:41 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:37:41 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:37:41 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 16:37:41.756617
2020-02-16 16:37:41 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 16:37:41 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 16:37:41 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 16:37:41 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 16:39:29 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:39:29.263766
2020-02-16 16:39:29 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:39:29 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:39:29 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:39:29 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:39:29 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:39:29 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 16:39:33 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:39:33.823027
2020-02-16 16:39:33 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04161DF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04161950>}
2020-02-16 16:39:33 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:39:33 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:39:33 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:39:33 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:39:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:40:00 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 16:43:15 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:43:15.276693
2020-02-16 16:43:15 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x041C2DB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x041C2910>}
2020-02-16 16:43:15 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:43:15 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:43:15 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:43:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:43:43 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:43:43.310297
2020-02-16 16:43:43 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04192DF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04192950>}
2020-02-16 16:43:43 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:43:43 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:43:43 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:44:44 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 16:44:44.581801
2020-02-16 16:44:44 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 16:44:44 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 16:44:44 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 16:44:44 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 16:44:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 16:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 16:44:45 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 16:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 16:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 16:44:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 16:44:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 16:44:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 16:44:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 16:44:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 16:44:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 16:44:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 16:44:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 16:44:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 16:44:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 16:44:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:16:34 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:16:34.693962
2020-02-16 18:16:34 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 18:16:34 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:16:34 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:16:34 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:16:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:16:34 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:16:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:16:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:16:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 18:16:42 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 18:16:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 18:16:43 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 18:16:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:16:45 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:16:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:16:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:16:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:16:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:16:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:16:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:16:47 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:16:48 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:16:48 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:16:48.033725
2020-02-16 18:16:48 engine.py[line:52]                   INFO: 耗时：13.34
2020-02-16 18:16:48 engine.py[line:53]                   INFO: 一共获取了请求：30个
2020-02-16 18:16:48 engine.py[line:54]                   INFO: 重复的请求：7个
2020-02-16 18:16:48 engine.py[line:55]                   INFO: 成功的请求：23个
2020-02-16 18:16:59 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:16:59.438377
2020-02-16 18:16:59 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 18:16:59 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:16:59 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:16:59 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:59 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:16:59 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:16:59.463378
2020-02-16 18:16:59 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 18:16:59 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 18:16:59 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 18:16:59 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:17:03 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:17:03.236594
2020-02-16 18:17:03 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 18:17:03 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:17:03 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:17:03 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:03 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:17:03.258595
2020-02-16 18:17:03 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 18:17:03 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 18:17:03 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 18:17:03 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:17:34 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:17:34.934407
2020-02-16 18:17:34 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307C10>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C90>}
2020-02-16 18:17:34 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:17:34 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:17:34 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:17:34 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:58 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:17:58.404750
2020-02-16 18:17:58 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03317C10>, 'doubai': <spiders.douban.DoubanSpider object at 0x03317C90>}
2020-02-16 18:17:58 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:17:58 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:17:58 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:17:58 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:15 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:18:15.340718
2020-02-16 18:18:15 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307C10>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C90>}
2020-02-16 18:18:15 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:18:15 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:18:15 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:18:15 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:18:51.246772
2020-02-16 18:18:51 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 18:18:51 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:18:51 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:18:51 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:18:51 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:18:51.274774
2020-02-16 18:18:51 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 18:18:51 engine.py[line:53]                   INFO: 一共获取了请求：40个
2020-02-16 18:18:51 engine.py[line:54]                   INFO: 重复的请求：40个
2020-02-16 18:18:51 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:19:12 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:19:12.611994
2020-02-16 18:19:12 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 18:19:12 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:19:12 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:19:12 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:12 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:19:12.634995
2020-02-16 18:19:12 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 18:19:12 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 18:19:12 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 18:19:12 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:19:18 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:19:18.798348
2020-02-16 18:19:18 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC30>}
2020-02-16 18:19:18 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:19:18 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:19:18 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:18 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:19:18.825349
2020-02-16 18:19:18 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 18:19:18 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 18:19:18 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 18:19:18 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:19:53 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:19:53.513333
2020-02-16 18:19:53 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330ABF0>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330AC70>}
2020-02-16 18:19:53 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:19:53 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:19:53 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:53 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:19:53 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:19:53.541335
2020-02-16 18:19:53 engine.py[line:52]                   INFO: 耗时：0.03
2020-02-16 18:19:53 engine.py[line:53]                   INFO: 一共获取了请求：10个
2020-02-16 18:19:53 engine.py[line:54]                   INFO: 重复的请求：10个
2020-02-16 18:19:53 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:27:32 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:27:32.042560
2020-02-16 18:27:32 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03309B70>, 'doubai': <spiders.douban.DoubanSpider object at 0x03309BF0>}
2020-02-16 18:27:32 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:27:32 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:27:32 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:27:32 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:27:32 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:27:32 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:27:32 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:27:32 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:27:32 engine.py[line:51]                   INFO: 结束运行时间：2020-02-16 18:27:32.064561
2020-02-16 18:27:32 engine.py[line:52]                   INFO: 耗时：0.02
2020-02-16 18:27:32 engine.py[line:53]                   INFO: 一共获取了请求：5个
2020-02-16 18:27:32 engine.py[line:54]                   INFO: 重复的请求：5个
2020-02-16 18:27:32 engine.py[line:55]                   INFO: 成功的请求：0个
2020-02-16 18:27:54 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:27:54.916868
2020-02-16 18:27:54 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03309B50>, 'doubai': <spiders.douban.DoubanSpider object at 0x03309BD0>}
2020-02-16 18:27:54 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:27:54 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:27:54 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:27:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:27:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:27:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:27:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:27:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:31:18 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:31:18.816530
2020-02-16 18:31:18 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C30>}
2020-02-16 18:31:18 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:31:18 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:31:18 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:31:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:31:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:31:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:31:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:31:18 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:31:54 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:31:54.458569
2020-02-16 18:31:54 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307B70>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307BF0>}
2020-02-16 18:31:54 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:31:54 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:31:54 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:31:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:31:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:31:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:31:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:31:54 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:32:12 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:32:12.979628
2020-02-16 18:32:12 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03307BB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03307C30>}
2020-02-16 18:32:12 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:32:12 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:32:12 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:32:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:32:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:32:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:32:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:32:12 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:32:40 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:32:40.169184
2020-02-16 18:32:40 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04161DB0>, 'doubai': <spiders.douban.DoubanSpider object at 0x04161910>}
2020-02-16 18:32:40 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:32:40 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:32:40 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:32:43 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:32:50 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:33:30 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:34:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:34:56 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:35:37 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:35:37.625333
2020-02-16 18:35:37 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04151D70>, 'doubai': <spiders.douban.DoubanSpider object at 0x041518D0>}
2020-02-16 18:35:37 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:35:37 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:35:37 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:35:41 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:35:44 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:35:47 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:35:52 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:36:19 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:40:07 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:40:07.667779
2020-02-16 18:40:07 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F75570>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F755F0>}
2020-02-16 18:40:07 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:40:07 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:40:07 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:40:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:40:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:40:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:40:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:40:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:41:03 engine.py[line:43]                   INFO: 开始运行时间：2020-02-16 18:41:03.622979
2020-02-16 18:41:03 engine.py[line:44]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F964D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F96550>}
2020-02-16 18:41:03 engine.py[line:45]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:41:03 engine.py[line:46]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:41:03 engine.py[line:48]                   INFO: 启用的管道有：[]
2020-02-16 18:41:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:41:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:41:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:41:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:41:03 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:46:06 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:46:06.970330
2020-02-16 18:46:06 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03FA34B0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03FA3530>}
2020-02-16 18:46:06 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:46:06 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:46:06 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:46:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:46:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:46:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:46:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:46:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:46:31 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:46:31.310722
2020-02-16 18:46:31 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03F434D0>, 'doubai': <spiders.douban.DoubanSpider object at 0x03F43550>}
2020-02-16 18:46:31 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:46:31 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:46:31 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:46:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:46:31 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:46:31 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:46:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:46:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:46:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 18:46:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 18:46:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 18:46:34 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 18:46:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:46:35 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:46:36 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:46:36 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:46:36 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:46:37 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:46:37 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:46:37 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:46:38 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:46:38 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:46:39 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:46:39 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:46:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:46:40 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:46:40 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:46:41 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:48:05 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:48:05.658118
2020-02-16 18:48:05 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03328B70>, 'doubai': <spiders.douban.DoubanSpider object at 0x03328BF0>}
2020-02-16 18:48:05 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:48:05 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:48:05 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:48:05 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:48:05 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:48:05 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:48:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:48:06 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:48:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 18:48:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 18:48:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 18:48:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 18:48:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:48:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:48:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:48:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:48:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:48:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:48:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:48:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:48:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:48:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:48:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:48:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:48:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:48:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:48:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:48:14 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:48:14 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:48:14.926649
2020-02-16 18:48:14 engine.py[line:54]                   INFO: 耗时：9.27
2020-02-16 18:48:14 engine.py[line:55]                   INFO: 一共获取了请求：25个
2020-02-16 18:48:14 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 18:48:14 engine.py[line:57]                   INFO: 成功的请求：23个
2020-02-16 18:48:52 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:48:52.591803
2020-02-16 18:48:52 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 18:48:52 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:48:52 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:48:52 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:48:52 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:48:52 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:48:52 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:48:52 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:48:52 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:48:52 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:48:52.609804
2020-02-16 18:48:52 engine.py[line:54]                   INFO: 耗时：0.02
2020-02-16 18:48:52 engine.py[line:55]                   INFO: 一共获取了请求：5个
2020-02-16 18:48:52 engine.py[line:56]                   INFO: 重复的请求：5个
2020-02-16 18:48:52 engine.py[line:57]                   INFO: 成功的请求：0个
2020-02-16 18:49:58 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:49:58.137552
2020-02-16 18:49:58 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04173D50>, 'doubai': <spiders.douban.DoubanSpider object at 0x041738B0>}
2020-02-16 18:49:58 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:49:58 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:49:58 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:50:07 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:50:07 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:50:07.808105
2020-02-16 18:50:07 engine.py[line:54]                   INFO: 耗时：9.67
2020-02-16 18:50:07 engine.py[line:55]                   INFO: 一共获取了请求：1个
2020-02-16 18:50:07 engine.py[line:56]                   INFO: 重复的请求：1个
2020-02-16 18:50:07 engine.py[line:57]                   INFO: 成功的请求：0个
2020-02-16 18:50:25 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:50:25.402111
2020-02-16 18:50:25 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x04192D50>, 'doubai': <spiders.douban.DoubanSpider object at 0x041928B0>}
2020-02-16 18:50:25 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:50:25 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:50:25 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:50:35 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:50:43 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:50:43.071122
2020-02-16 18:50:43 engine.py[line:54]                   INFO: 耗时：17.67
2020-02-16 18:50:43 engine.py[line:55]                   INFO: 一共获取了请求：1个
2020-02-16 18:50:43 engine.py[line:56]                   INFO: 重复的请求：1个
2020-02-16 18:50:43 engine.py[line:57]                   INFO: 成功的请求：0个
2020-02-16 18:52:53 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:52:53.939607
2020-02-16 18:52:53 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 18:52:53 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:52:53 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:52:53 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:52:56 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:52:56 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:52:56 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:52:56 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 18:52:56 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 18:52:56 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:52:56.954780
2020-02-16 18:52:56 engine.py[line:54]                   INFO: 耗时：3.02
2020-02-16 18:52:56 engine.py[line:55]                   INFO: 一共获取了请求：5个
2020-02-16 18:52:56 engine.py[line:56]                   INFO: 重复的请求：5个
2020-02-16 18:52:56 engine.py[line:57]                   INFO: 成功的请求：0个
2020-02-16 18:58:07 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:58:07.784558
2020-02-16 18:58:07 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 18:58:07 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:58:07 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:58:07 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:58:10 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:58:10 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:58:11 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:58:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:58:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:58:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 18:58:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 18:58:12 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 18:58:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 18:58:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:58:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:58:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:58:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:58:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:58:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:58:16 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:58:16 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:58:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:58:17 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:58:17 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:58:18 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:58:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:58:19 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:58:19 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:58:19 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:58:19 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:58:19.838248
2020-02-16 18:58:19 engine.py[line:54]                   INFO: 耗时：12.05
2020-02-16 18:58:19 engine.py[line:55]                   INFO: 一共获取了请求：25个
2020-02-16 18:58:19 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 18:58:19 engine.py[line:57]                   INFO: 成功的请求：23个
2020-02-16 18:58:23 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:58:23.383450
2020-02-16 18:58:23 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 18:58:23 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:58:23 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:58:23 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:58:23 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:58:23 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:58:23 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:58:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:58:24 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:58:25 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 18:58:25 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 18:58:25 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 18:58:26 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455998/>
2020-02-16 18:58:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:58:27 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:58:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:58:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:58:29 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:58:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:58:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:58:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:58:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:58:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:58:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:58:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:58:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:58:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:58:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:58:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:58:33 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:58:33.340020
2020-02-16 18:58:33 engine.py[line:54]                   INFO: 耗时：9.96
2020-02-16 18:58:33 engine.py[line:55]                   INFO: 一共获取了请求：25个
2020-02-16 18:58:33 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 18:58:33 engine.py[line:57]                   INFO: 成功的请求：23个
2020-02-16 18:58:48 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:58:48.970914
2020-02-16 18:58:48 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 18:58:48 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:58:48 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:58:48 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:58:49 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:58:49 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:58:49 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:58:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:58:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:58:50 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:58:51 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:58:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:58:51 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:58:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:58:52 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:58:52 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:58:52 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:58:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:58:53 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:58:54 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 18:58:55 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 18:58:59 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 18:59:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 18:59:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:59:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:59:02 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:59:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:59:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:59:03 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:59:03 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:59:03.331735
2020-02-16 18:59:03 engine.py[line:54]                   INFO: 耗时：14.36
2020-02-16 18:59:03 engine.py[line:55]                   INFO: 一共获取了请求：25个
2020-02-16 18:59:03 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 18:59:03 engine.py[line:57]                   INFO: 成功的请求：23个
2020-02-16 18:59:06 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 18:59:06.718929
2020-02-16 18:59:06 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330AB50>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330ABD0>}
2020-02-16 18:59:06 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 18:59:06 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 18:59:06 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 18:59:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:59:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 18:59:06 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 18:59:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:59:07 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 18:59:08 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 18:59:09 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 18:59:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 18:59:10 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 18:59:10 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 18:59:11 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 18:59:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 18:59:12 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 18:59:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 18:59:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 18:59:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 18:59:13 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 18:59:13 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 18:59:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 18:59:14 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 18:59:15 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 18:59:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 18:59:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 18:59:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 18:59:15 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 18:59:15 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 18:59:15.733445
2020-02-16 18:59:15 engine.py[line:54]                   INFO: 耗时：9.01
2020-02-16 18:59:15 engine.py[line:55]                   INFO: 一共获取了请求：25个
2020-02-16 18:59:15 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 18:59:15 engine.py[line:57]                   INFO: 成功的请求：23个
2020-02-16 19:16:55 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 19:16:55.449057
2020-02-16 19:16:55 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330AB50>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330ABD0>}
2020-02-16 19:16:55 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 19:16:55 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 19:16:55 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 19:16:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:16:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:16:55 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 19:16:55.459057
2020-02-16 19:16:55 engine.py[line:54]                   INFO: 耗时：0.01
2020-02-16 19:16:55 engine.py[line:55]                   INFO: 一共获取了请求：3个
2020-02-16 19:16:55 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 19:16:55 engine.py[line:57]                   INFO: 成功的请求：0个
2020-02-16 19:16:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:16:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 19:16:55 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 19:17:11 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 19:17:11.609981
2020-02-16 19:17:11 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 19:17:11 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 19:17:11 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 19:17:11 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 19:17:11 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:17:11 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:17:16 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 19:17:25 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 19:17:28 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 19:17:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 19:17:28 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 19:17:29 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 19:17:29 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 19:17:30 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 19:17:30 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 19:17:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 19:17:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 19:17:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 19:17:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 19:17:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 19:19:37 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 19:19:37.019298
2020-02-16 19:19:37 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330AB50>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330ABD0>}
2020-02-16 19:19:37 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 19:19:37 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 19:19:37 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 19:19:37 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:19:37 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:19:39 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 19:19:39.669450
2020-02-16 19:19:39 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 19:19:39 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 19:19:39 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 19:19:39 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 19:19:39 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:19:39 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:19:39 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:19:39 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 19:19:39 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 19:19:40 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 19:19:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 19:19:40 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 19:19:45 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 19:19:46 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 19:19:46 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 19:19:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456004/>
2020-02-16 19:19:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/456014/>
2020-02-16 19:19:50 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455997/>
2020-02-16 19:20:00 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 19:20:18 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 19:20:18 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 19:20:19 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 19:20:21 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 19:20:21 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 19:20:21 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 19:21:26 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 19:21:26.954586
2020-02-16 19:21:26 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x03308B90>, 'doubai': <spiders.douban.DoubanSpider object at 0x03308C10>}
2020-02-16 19:21:26 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 19:21:26 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 19:21:26 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 19:21:26 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:21:26 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:21:30 downloader.py[line:19]                   INFO: <200 http://www.baidu.com/>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=2&wd=%E9%97%AE%E7%AD%94>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/search/all/?page=1&wd=%E9%97%AE%E7%AD%94>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455653/>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455318/>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686212/>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/684986/>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449701/>
2020-02-16 19:21:31 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818751/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449803/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/818716/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/446357/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/449842/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456004/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/456014/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455997/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//article/455998/>
2020-02-16 19:21:32 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//question/686763/>
2020-02-16 19:21:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com//post/819114/>
2020-02-16 19:21:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455095/>
2020-02-16 19:21:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455011/>
2020-02-16 19:21:33 downloader.py[line:19]                   INFO: <400 https://www.guokr.com//article/455847/>
2020-02-16 19:21:33 downloader.py[line:19]                   INFO: <200 https://www.guokr.com/group/close>
2020-02-16 19:21:33 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 19:21:33.353952
2020-02-16 19:21:33 engine.py[line:54]                   INFO: 耗时：6.40
2020-02-16 19:21:33 engine.py[line:55]                   INFO: 一共获取了请求：25个
2020-02-16 19:21:33 engine.py[line:56]                   INFO: 重复的请求：2个
2020-02-16 19:21:33 engine.py[line:57]                   INFO: 成功的请求：23个
2020-02-16 19:22:06 engine.py[line:45]                   INFO: 开始运行时间：2020-02-16 19:22:06.847868
2020-02-16 19:22:06 engine.py[line:46]                   INFO: 运行的爬虫有：{'baidu': <spiders.baidu.BaiduSpider object at 0x0330AB50>, 'doubai': <spiders.douban.DoubanSpider object at 0x0330ABD0>}
2020-02-16 19:22:06 engine.py[line:47]                   INFO: 开启的爬虫中间件有：[]
2020-02-16 19:22:06 engine.py[line:48]                   INFO: 开启的下载中间件有：[]
2020-02-16 19:22:06 engine.py[line:50]                   INFO: 启用的管道有：[]
2020-02-16 19:22:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:22:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:22:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<http://www.baidu.com>
2020-02-16 19:22:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=1&wd=问答>
2020-02-16 19:22:06 scheduler.py[line:54]                   INFO: 发现重复的请求：<https://www.guokr.com/search/all/?page=2&wd=问答>
2020-02-16 19:22:06 engine.py[line:53]                   INFO: 结束运行时间：2020-02-16 19:22:06.878870
2020-02-16 19:22:06 engine.py[line:54]                   INFO: 耗时：0.03
2020-02-16 19:22:06 engine.py[line:55]                   INFO: 一共获取了请求：5个
2020-02-16 19:22:06 engine.py[line:56]                   INFO: 重复的请求：5个
2020-02-16 19:22:06 engine.py[line:57]                   INFO: 成功的请求：0个
